{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # GPU 0,1,2 ì‚¬ìš©\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e680b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ê¸°ì¡´ ì½”ë“œ (ë°ì´í„° ë§¤ì¹­, ë°ì´í„°ì…‹, ë³€í™˜)\n",
    "# ===============================\n",
    "\n",
    "def match_image_mask_pairs(original_root, mask_root):\n",
    "    \"\"\"ì›ë³¸ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ íŒŒì¼ì„ ë§¤ì¹­\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"ğŸ“Š ë°ì´í„° ë§¤ì¹­ ë° ìˆ˜ì§‘\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ” ë°ì´í„° ë§¤ì¹­ ì‹œì‘\")\n",
    "    print(f\"  ì›ë³¸ ì´ë¯¸ì§€: {original_root}\")\n",
    "    print(f\"  ë§ˆìŠ¤í¬ ì´ë¯¸ì§€: {mask_root}\")\n",
    "    \n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "    \n",
    "    original_root = Path(original_root)\n",
    "    mask_root = Path(mask_root)\n",
    "    \n",
    "    # í´ë” ë§¤í•‘ í…Œì´ë¸”\n",
    "    folder_mapping = {\n",
    "        'Fr5_intertek_1st_250526': '1st',\n",
    "        'Fr5_intertek_2nd_250526': '2nd', \n",
    "        'Fr5_intertek_3rd_250526': '3rd',\n",
    "        'Fr5_intertek_4th_250526': '4th',\n",
    "        'Fr5_intertek_5th_250526': '5th',\n",
    "        'Fr5_intertek_6th_250526': '6th',\n",
    "        'Fr5_intertek_7th_250526': '7th'\n",
    "    }\n",
    "    \n",
    "    total_pairs = 0\n",
    "    \n",
    "    for original_folder, mask_folder in folder_mapping.items():\n",
    "        original_folder_path = original_root / original_folder\n",
    "        mask_folder_path = mask_root / mask_folder\n",
    "        \n",
    "        if not original_folder_path.exists():\n",
    "            print(f\"âš ï¸  ì›ë³¸ í´ë” ì—†ìŒ: {original_folder_path}\")\n",
    "            continue\n",
    "            \n",
    "        if not mask_folder_path.exists():\n",
    "            print(f\"âš ï¸  ë§ˆìŠ¤í¬ í´ë” ì—†ìŒ: {mask_folder_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"ğŸ“ ì²˜ë¦¬ ì¤‘: {original_folder} â†’ {mask_folder}\")\n",
    "        \n",
    "        # left, right, top ì‹œì ë³„ ì²˜ë¦¬\n",
    "        for view in ['left', 'right', 'top']:\n",
    "            original_view_path = original_folder_path / view\n",
    "            mask_view_path = mask_folder_path / view / 'masks'\n",
    "            \n",
    "            if not original_view_path.exists():\n",
    "                print(f\"  âš ï¸  ì›ë³¸ {view} í´ë” ì—†ìŒ\")\n",
    "                continue\n",
    "                \n",
    "            if not mask_view_path.exists():\n",
    "                print(f\"  âš ï¸  ë§ˆìŠ¤í¬ {view}/masks í´ë” ì—†ìŒ: {mask_view_path}\")\n",
    "                continue\n",
    "            \n",
    "            view_pairs = 0\n",
    "            unmatched_samples = []\n",
    "            \n",
    "            # ì›ë³¸ ì´ë¯¸ì§€ë“¤ ì°¾ê¸°\n",
    "            for img_ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG']:\n",
    "                for original_img_path in original_view_path.glob(img_ext):\n",
    "                    # ë§ˆìŠ¤í¬ íŒŒì¼ëª… íŒ¨í„´ë“¤ ì‹œë„\n",
    "                    possible_mask_names = [\n",
    "                        f\"{original_img_path.stem}_mask.png\",\n",
    "                        f\"{original_img_path.stem}.png\",\n",
    "                        f\"{original_img_path.name.replace('.jpg', '_mask.png')}\",\n",
    "                        f\"{original_img_path.name.replace('.JPG', '_mask.png')}\",\n",
    "                        f\"{original_img_path.name.replace('.jpeg', '_mask.png')}\",\n",
    "                        f\"{original_img_path.name.replace('.JPEG', '_mask.png')}\"\n",
    "                    ]\n",
    "                    \n",
    "                    found = False\n",
    "                    for possible_name in possible_mask_names:\n",
    "                        possible_mask_path = mask_view_path / possible_name\n",
    "                        if possible_mask_path.exists():\n",
    "                            image_paths.append(str(original_img_path))\n",
    "                            mask_paths.append(str(possible_mask_path))\n",
    "                            view_pairs += 1\n",
    "                            found = True\n",
    "                            break\n",
    "                    \n",
    "                    if not found:\n",
    "                        unmatched_samples.append(original_img_path.name)\n",
    "            \n",
    "            if view_pairs > 0:\n",
    "                print(f\"  âœ… {view}: {view_pairs}ê°œ ë§¤ì¹­ ìŒ\")\n",
    "                total_pairs += view_pairs\n",
    "                \n",
    "                if unmatched_samples:\n",
    "                    print(f\"    âš ï¸  ë§¤ì¹­ ì‹¤íŒ¨ ({len(unmatched_samples)}ê°œ): {unmatched_samples[:3]}\")\n",
    "            else:\n",
    "                print(f\"  âŒ {view}: ë§¤ì¹­ ì‹¤íŒ¨\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    return image_paths, mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotArmDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None, is_train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ì›ë³¸ RGB ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}\")\n",
    "            \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if mask is None:\n",
    "            raise ValueError(f\"ë§ˆìŠ¤í¬ ë¡œë“œ ì‹¤íŒ¨: {mask_path}\")\n",
    "        \n",
    "        # ë§ˆìŠ¤í¬ë¥¼ ì´ì§„í™” (0: ë°°ê²½, 1: ë¡œë´‡íŒ”)\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "        \n",
    "        # ë³€í™˜ ì ìš©\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'mask': mask.long(),\n",
    "            'image_path': image_path,\n",
    "            'mask_path': mask_path\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms(image_size=512, augmentation_level='moderate'):\n",
    "    \"\"\"\n",
    "    ë°ì´í„° ì¦ê°• ì„¤ì •\n",
    "    augmentation_level: 'light', 'moderate', 'heavy'\n",
    "    \"\"\"\n",
    "    \n",
    "    if augmentation_level == 'light':\n",
    "        # ê°€ë²¼ìš´ ì¦ê°• (ë¹ ë¥¸ í›ˆë ¨, ì•ˆì •ì )\n",
    "        return A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    elif augmentation_level == 'moderate':\n",
    "        # ì¤‘ê°„ ì¦ê°• (ê· í˜•ì¡íŒ ì„±ëŠ¥, ê¶Œì¥)\n",
    "        return A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1, \n",
    "                scale_limit=0.1, \n",
    "                rotate_limit=15, \n",
    "                p=0.5\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2, \n",
    "                contrast_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=10, \n",
    "                sat_shift_limit=20, \n",
    "                val_shift_limit=10, \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=(10, 50), p=0.3),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    elif augmentation_level == 'heavy':\n",
    "        # ê°•í•œ ì¦ê°• (ë¡œë´‡íŒ” íŠ¹í™”, ë” robustí•œ ëª¨ë¸)\n",
    "        return A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            \n",
    "            # ê¸°í•˜í•™ì  ë³€í™˜ (ë¡œë´‡íŒ”ì˜ ë‹¤ì–‘í•œ ìì„¸)\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.3),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Rotate(limit=30, p=0.5),  # ë” í° íšŒì „ê°\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.15, \n",
    "                scale_limit=0.15, \n",
    "                rotate_limit=20, \n",
    "                p=0.6\n",
    "            ),\n",
    "            \n",
    "            # ìƒ‰ìƒ/ì¡°ëª… ë³€í™˜ (ë‹¤ì–‘í•œ í™˜ê²½ ì¡°ê±´)\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.3, \n",
    "                contrast_limit=0.3, \n",
    "                p=0.6\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=15, \n",
    "                sat_shift_limit=30, \n",
    "                val_shift_limit=15, \n",
    "                p=0.4\n",
    "            ),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "            A.CLAHE(clip_limit=2.0, p=0.3),  # ëŒ€ë¹„ ê°œì„ \n",
    "            \n",
    "            # ë…¸ì´ì¦ˆ ë° ë¸”ëŸ¬ (ì¹´ë©”ë¼ í’ˆì§ˆ ì‹œë®¬ë ˆì´ì…˜)\n",
    "            A.GaussNoise(var_limit=(10, 80), p=0.4),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.2),\n",
    "            A.MotionBlur(blur_limit=3, p=0.2),\n",
    "            \n",
    "            # ê°€ë ¤ì§ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ í™˜ê²½ì˜ ì¥ì• ë¬¼)\n",
    "            A.CoarseDropout(\n",
    "                max_holes=3, \n",
    "                max_height=32, \n",
    "                max_width=32, \n",
    "                min_holes=1, \n",
    "                min_height=8, \n",
    "                min_width=8, \n",
    "                p=0.3\n",
    "            ),\n",
    "            \n",
    "            # ê·¸ë¦¼ì íš¨ê³¼ (ì¡°ëª… ë³€í™”) - ì¼ë¶€ ë²„ì „ì—ì„œ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\n",
    "            # A.RandomShadow(\n",
    "            #     shadow_roi=(0, 0.5, 1, 1),\n",
    "            #     num_shadows_lower=1,\n",
    "            #     num_shadows_upper=2,\n",
    "            #     shadow_dimension=5,\n",
    "            #     p=0.3\n",
    "            # ),\n",
    "            \n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"augmentation_level must be 'light', 'moderate', or 'heavy'\")\n",
    "\n",
    "def get_val_transforms(image_size=512):\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def debug_tensor_shapes(images, masks, outputs, step_name=\"\"):\n",
    "    \"\"\"í…ì„œ í¬ê¸° ë””ë²„ê¹…ìš© í•¨ìˆ˜\"\"\"\n",
    "    print(f\"\\nğŸ” {step_name} í…ì„œ í¬ê¸°:\")\n",
    "    print(f\"  ì…ë ¥ ì´ë¯¸ì§€: {images.shape}\")\n",
    "    print(f\"  íƒ€ê²Ÿ ë§ˆìŠ¤í¬: {masks.shape}\")\n",
    "    print(f\"  ëª¨ë¸ ì¶œë ¥: {outputs.shape}\")\n",
    "    \n",
    "    if images.shape[-2:] != outputs.shape[-2:]:\n",
    "        print(f\"  âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜ ê°ì§€!\")\n",
    "        print(f\"    ì…ë ¥ í¬ê¸°: {images.shape[-2:]}\")\n",
    "        print(f\"    ì¶œë ¥ í¬ê¸°: {outputs.shape[-2:]}\")\n",
    "    else:\n",
    "        print(f\"  âœ… í¬ê¸° ì¼ì¹˜ í™•ì¸\")\n",
    "    \"\"\"ë°ì´í„° í’ˆì§ˆ ê²€ì¦\"\"\"\n",
    "    print(f\"\\nğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (ìƒ˜í”Œ {num_samples}ê°œ)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for i in range(min(num_samples, len(image_paths))):\n",
    "        img_path = image_paths[i]\n",
    "        mask_path = mask_paths[i]\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ ìƒ˜í”Œ {i+1}:\")\n",
    "        print(f\"  ì›ë³¸: {Path(img_path).name}\")\n",
    "        print(f\"  ë§ˆìŠ¤í¬: {Path(mask_path).name}\")\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"  âŒ ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "                continue\n",
    "                \n",
    "            if mask is None:\n",
    "                print(f\"  âŒ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  ğŸ“ ì›ë³¸ í¬ê¸°: {img.shape}\")\n",
    "            print(f\"  ğŸ“ ë§ˆìŠ¤í¬ í¬ê¸°: {mask.shape}\")\n",
    "            \n",
    "            unique_values = np.unique(mask)\n",
    "            print(f\"  ğŸ¨ ë§ˆìŠ¤í¬ í”½ì…€ê°’: {unique_values}\")\n",
    "            \n",
    "            robot_pixels = np.sum(mask > 127)\n",
    "            total_pixels = mask.shape[0] * mask.shape[1]\n",
    "            robot_ratio = robot_pixels / total_pixels * 100\n",
    "            print(f\"  ğŸ¤– ë¡œë´‡íŒ” ë¹„ìœ¨: {robot_ratio:.1f}%\")\n",
    "            \n",
    "            print(f\"  âœ… ì •ìƒ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10474d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ë“¤\n",
    "# ===============================\n",
    "\n",
    "def calculate_iou(pred, target, num_classes=2):\n",
    "    \"\"\"IoU ê³„ì‚°\"\"\"\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        target_cls = (target == cls)\n",
    "        \n",
    "        intersection = torch.logical_and(pred_cls, target_cls).sum()\n",
    "        union = torch.logical_or(pred_cls, target_cls).sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = 1.0  # í•´ë‹¹ í´ë˜ìŠ¤ê°€ ì—†ëŠ” ê²½ìš°\n",
    "        else:\n",
    "            iou = intersection.float() / union.float()\n",
    "        \n",
    "        ious.append(iou)\n",
    "    \n",
    "    return torch.stack(ious)\n",
    "\n",
    "def calculate_dice(pred, target, num_classes=2):\n",
    "    \"\"\"Dice Score ê³„ì‚°\"\"\"\n",
    "    dices = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        target_cls = (target == cls)\n",
    "        \n",
    "        intersection = torch.logical_and(pred_cls, target_cls).sum()\n",
    "        total = pred_cls.sum() + target_cls.sum()\n",
    "        \n",
    "        if total == 0:\n",
    "            dice = 1.0  # í•´ë‹¹ í´ë˜ìŠ¤ê°€ ì—†ëŠ” ê²½ìš°\n",
    "        else:\n",
    "            dice = (2.0 * intersection.float()) / total.float()\n",
    "        \n",
    "        dices.append(dice)\n",
    "    \n",
    "    return torch.stack(dices)\n",
    "\n",
    "def calculate_pixel_accuracy(pred, target):\n",
    "    \"\"\"Pixel Accuracy ê³„ì‚°\"\"\"\n",
    "    correct = (pred == target).sum()\n",
    "    total = target.numel()\n",
    "    return correct.float() / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SegFormer ëª¨ë¸ ì •ì˜\n",
    "# ===============================\n",
    "\n",
    "class SegFormerForRobotArm(nn.Module):\n",
    "    def __init__(self, num_classes=2, model_name=\"nvidia/mit-b2\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # SegFormer ëª¨ë¸ ë¡œë“œ (pretrained MiT ë°±ë³¸ í¬í•¨)\n",
    "        # model_name ì˜µì…˜:\n",
    "        # - nvidia/mit-b0: 3.7M params (ë¹ ë¦„, ê°€ë²¼ì›€)\n",
    "        # - nvidia/mit-b1: 14M params  \n",
    "        # - nvidia/mit-b2: 25M params (ê¶Œì¥, ê· í˜•ì )\n",
    "        # - nvidia/mit-b3: 45M params (ë” ë†’ì€ ì„±ëŠ¥)\n",
    "        # - nvidia/mit-b4: 62M params\n",
    "        # - nvidia/mit-b5: 82M params (ìµœê³  ì„±ëŠ¥, ëŠë¦¼)\n",
    "        \n",
    "        print(f\"ğŸ—ï¸ SegFormer ëª¨ë¸ ë¡œë”©: {model_name}\")\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥\n",
    "        total_params = sum(p.numel() for p in self.segformer.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.segformer.parameters() if p.requires_grad)\n",
    "        print(f\"ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {total_params:,}\")\n",
    "        print(f\"ğŸ“Š í›ˆë ¨ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}\")\n",
    "        \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.segformer(pixel_values=pixel_values)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # SegFormer ì¶œë ¥ì„ ì…ë ¥ í¬ê¸°ë¡œ ì—…ìƒ˜í”Œë§\n",
    "        # ì…ë ¥: [B, C, H, W] -> ì¶œë ¥: [B, num_classes, H, W]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=pixel_values.shape[-2:],  # (H, W)\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        return upsampled_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
    "# ===============================\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # CrossEntropyLoss ê°€ì¤‘ì¹˜\n",
    "        self.beta = beta    # DiceLoss ê°€ì¤‘ì¹˜\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def dice_loss(self, pred, target, smooth=1e-6):\n",
    "        \"\"\"Dice Loss ê³„ì‚°\"\"\"\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        \n",
    "        dice_losses = []\n",
    "        for cls in range(pred.shape[1]):\n",
    "            pred_cls = pred[:, cls, :, :]\n",
    "            target_cls = (target == cls).float()\n",
    "            \n",
    "            intersection = (pred_cls * target_cls).sum(dim=(1, 2))\n",
    "            union = pred_cls.sum(dim=(1, 2)) + target_cls.sum(dim=(1, 2))\n",
    "            \n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_loss = 1.0 - dice\n",
    "            dice_losses.append(dice_loss.mean())\n",
    "        \n",
    "        return sum(dice_losses) / len(dice_losses)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce_loss = self.ce_loss(pred, target)\n",
    "        dice_loss = self.dice_loss(pred, target)\n",
    "        \n",
    "        total_loss = self.alpha * ce_loss + self.beta * dice_loss\n",
    "        return total_loss, ce_loss, dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2abbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# í›ˆë ¨ ë° ê²€ì¦ í•¨ìˆ˜\n",
    "# ===============================\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"í•œ ì—í¬í¬ í›ˆë ¨\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_ce_loss = 0.0\n",
    "    running_dice_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice_score = 0.0\n",
    "    running_pixel_acc = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Train Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        images = batch['image'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # ëª¨ë¸ ì˜ˆì¸¡\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ í¬ê¸° í™•ì¸ (ë””ë²„ê¹…ìš©)\n",
    "        if batch_idx == 0 and epoch == 1:\n",
    "            print(f\"\\nğŸ” ì²« ë²ˆì§¸ í›ˆë ¨ ë°°ì¹˜ í…ì„œ í¬ê¸°:\")\n",
    "            print(f\"  ì…ë ¥ ì´ë¯¸ì§€: {images.shape}\")\n",
    "            print(f\"  íƒ€ê²Ÿ ë§ˆìŠ¤í¬: {masks.shape}\")\n",
    "            print(f\"  ëª¨ë¸ ì¶œë ¥: {outputs.shape}\")\n",
    "            \n",
    "            if images.shape[-2:] != outputs.shape[-2:]:\n",
    "                print(f\"  âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜ ê°ì§€!\")\n",
    "                print(f\"    ì…ë ¥ í¬ê¸°: {images.shape[-2:]}\")\n",
    "                print(f\"    ì¶œë ¥ í¬ê¸°: {outputs.shape[-2:]}\")\n",
    "            else:\n",
    "                print(f\"  âœ… í¬ê¸° ì¼ì¹˜ í™•ì¸\")\n",
    "        \n",
    "        # ì†ì‹¤ ê³„ì‚°\n",
    "        loss, ce_loss, dice_loss = criterion(outputs, masks)\n",
    "        \n",
    "        # ì—­ì „íŒŒ\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\n",
    "        with torch.no_grad():\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            iou = calculate_iou(pred_masks, masks).mean()\n",
    "            dice_score = calculate_dice(pred_masks, masks).mean()\n",
    "            pixel_acc = calculate_pixel_accuracy(pred_masks, masks)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_ce_loss += ce_loss.item()\n",
    "            running_dice_loss += dice_loss.item()\n",
    "            running_iou += iou.item()\n",
    "            running_dice_score += dice_score.item()\n",
    "            running_pixel_acc += pixel_acc.item()\n",
    "        \n",
    "        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "        if batch_idx % 10 == 0:\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'IoU': f'{iou.item():.4f}',\n",
    "                'Dice': f'{dice_score.item():.4f}',\n",
    "                'PixelAcc': f'{pixel_acc.item():.4f}'\n",
    "            })\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    return {\n",
    "        'loss': running_loss / num_batches,\n",
    "        'ce_loss': running_ce_loss / num_batches,\n",
    "        'dice_loss': running_dice_loss / num_batches,\n",
    "        'iou': running_iou / num_batches,\n",
    "        'dice_score': running_dice_score / num_batches,\n",
    "        'pixel_accuracy': running_pixel_acc / num_batches\n",
    "    }\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device, epoch):\n",
    "    \"\"\"í•œ ì—í¬í¬ ê²€ì¦\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_ce_loss = 0.0\n",
    "    running_dice_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice_score = 0.0\n",
    "    running_pixel_acc = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=f'Val Epoch {epoch}')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            # ëª¨ë¸ ì˜ˆì¸¡\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # ì†ì‹¤ ê³„ì‚°\n",
    "            loss, ce_loss, dice_loss = criterion(outputs, masks)\n",
    "            \n",
    "            # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            iou = calculate_iou(pred_masks, masks).mean()\n",
    "            dice_score = calculate_dice(pred_masks, masks).mean()\n",
    "            pixel_acc = calculate_pixel_accuracy(pred_masks, masks)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_ce_loss += ce_loss.item()\n",
    "            running_dice_loss += dice_loss.item()\n",
    "            running_iou += iou.item()\n",
    "            running_dice_score += dice_score.item()\n",
    "            running_pixel_acc += pixel_acc.item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'IoU': f'{iou.item():.4f}',\n",
    "                'Dice': f'{dice_score.item():.4f}',\n",
    "                'PixelAcc': f'{pixel_acc.item():.4f}'\n",
    "            })\n",
    "    \n",
    "    num_batches = len(val_loader)\n",
    "    return {\n",
    "        'loss': running_loss / num_batches,\n",
    "        'ce_loss': running_ce_loss / num_batches,\n",
    "        'dice_loss': running_dice_loss / num_batches,\n",
    "        'iou': running_iou / num_batches,\n",
    "        'dice_score': running_dice_score / num_batches,\n",
    "        'pixel_accuracy': running_pixel_acc / num_batches\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜\n",
    "# ===============================\n",
    "\n",
    "def visualize_predictions(model, val_loader, device, num_samples=3):\n",
    "    \"\"\"ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # ì—­ì •ê·œí™”ë¥¼ ìœ„í•œ í•¨ìˆ˜\n",
    "    def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        for t, m, s in zip(tensor, mean, std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return torch.clamp(tensor, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ì‹œê°í™”\n",
    "            image = images[0].cpu()\n",
    "            mask = masks[0].cpu().numpy()\n",
    "            pred_mask = pred_masks[0].cpu().numpy()\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ì—­ì •ê·œí™”\n",
    "            image = denormalize(image)\n",
    "            image = image.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # ì›ë³¸ ì´ë¯¸ì§€\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # ì‹¤ì œ ë§ˆìŠ¤í¬\n",
    "            axes[i, 1].imshow(mask, cmap='gray')\n",
    "            axes[i, 1].set_title(f'Ground Truth Mask {i+1}')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # ì˜ˆì¸¡ ë§ˆìŠ¤í¬\n",
    "            axes[i, 2].imshow(pred_mask, cmap='gray')\n",
    "            axes[i, 2].set_title(f'Predicted Mask {i+1}')\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49891e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ë©”ì¸ í›ˆë ¨ í•¨ìˆ˜\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    BATCH_SIZE = 8  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •\n",
    "    IMAGE_SIZE = 512\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_EPOCHS = 50\n",
    "    PATIENCE = 10  # Early stopping\n",
    "    \n",
    "    # ëª¨ë¸ í¬ê¸° ì„ íƒ (ì„±ëŠ¥ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„)\n",
    "    MODEL_VARIANTS = {\n",
    "        'small': 'nvidia/mit-b0',    # ë¹ ë¦„, ê°€ë²¼ì›€\n",
    "        'medium': 'nvidia/mit-b2',   # ê¶Œì¥ (ê· í˜•ì )\n",
    "        'large': 'nvidia/mit-b3',    # ë†’ì€ ì„±ëŠ¥\n",
    "        'xlarge': 'nvidia/mit-b4'    # ìµœê³  ì„±ëŠ¥ (ë©”ëª¨ë¦¬ ë§ì´ í•„ìš”)\n",
    "    }\n",
    "    \n",
    "    # ì¦ê°• ë ˆë²¨ ì„ íƒ\n",
    "    AUGMENTATION_LEVELS = {\n",
    "        'light': 'ê°€ë²¼ìš´ ì¦ê°• (ë¹ ë¥¸ í›ˆë ¨)',\n",
    "        'moderate': 'ì¤‘ê°„ ì¦ê°• (ê¶Œì¥)',\n",
    "        'heavy': 'ê°•í•œ ì¦ê°• (ë” robustí•œ ëª¨ë¸)'\n",
    "    }\n",
    "    \n",
    "    # ì„¤ì • (í•„ìš”ì— ë”°ë¼ ë³€ê²½)\n",
    "    MODEL_SIZE = 'medium'  # 'small', 'medium', 'large', 'xlarge'\n",
    "    AUGMENTATION_LEVEL = 'moderate'  # 'light', 'moderate', 'heavy'\n",
    "    \n",
    "    print(\"ğŸš€ SegFormer ë¡œë´‡íŒ” Segmentation í›ˆë ¨ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ—ï¸ ëª¨ë¸ í¬ê¸°: {MODEL_SIZE} ({MODEL_VARIANTS[MODEL_SIZE]})\")\n",
    "    print(f\"ğŸ”„ ë°ì´í„° ì¦ê°•: {AUGMENTATION_LEVEL} ({AUGMENTATION_LEVELS[AUGMENTATION_LEVEL]})\")\n",
    "    \n",
    "    # 1. ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    \n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        print(\"âŒ ë§¤ì¹­ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # 2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦\n",
    "    # verify_data_quality(image_paths, mask_paths, num_samples=3)\n",
    "    \n",
    "    # 3. Train/Validation ë¶„í•  (stratified by view)\n",
    "    # ì‹œì  ì •ë³´ ì¶”ì¶œ (ê²½ë¡œì—ì„œ)\n",
    "    views = []\n",
    "    for img_path in image_paths:\n",
    "        if 'left' in img_path:\n",
    "            views.append('left')\n",
    "        elif 'right' in img_path:\n",
    "            views.append('right')\n",
    "        elif 'top' in img_path:\n",
    "            views.append('top')\n",
    "        else:\n",
    "            views.append('unknown')\n",
    "    \n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "        image_paths, mask_paths,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=views\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í•  ê²°ê³¼:\")\n",
    "    print(f\"  í›ˆë ¨ ë°ì´í„°: {len(train_img_paths)}ê°œ\")\n",
    "    print(f\"  ê²€ì¦ ë°ì´í„°: {len(val_img_paths)}ê°œ\")\n",
    "    \n",
    "    # 4. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "    train_transforms = get_train_transforms(IMAGE_SIZE, AUGMENTATION_LEVEL)\n",
    "    val_transforms = get_val_transforms(IMAGE_SIZE)\n",
    "    \n",
    "    train_dataset = RobotArmDataset(\n",
    "        train_img_paths, train_mask_paths, \n",
    "        transform=train_transforms, \n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = RobotArmDataset(\n",
    "        val_img_paths, val_mask_paths, \n",
    "        transform=val_transforms, \n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ ë°°ì¹˜ ì •ë³´:\")\n",
    "    print(f\"  í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "    print(f\"  ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}\")\n",
    "    print(f\"  ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}\")\n",
    "    \n",
    "    # 5. ëª¨ë¸ ìƒì„±\n",
    "    print(f\"\\nğŸ—ï¸ ëª¨ë¸ ìƒì„± ì¤‘...\")\n",
    "    model = SegFormerForRobotArm(\n",
    "        num_classes=2, \n",
    "        model_name=MODEL_VARIANTS[MODEL_SIZE]\n",
    "    )\n",
    "    \n",
    "    # Multi-GPU ì‚¬ìš©\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"ğŸ–¥ï¸ {torch.cuda.device_count()}ê°œ GPU ì‚¬ìš©\")\n",
    "        model = DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 6. ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
    "    criterion = CombinedLoss(alpha=0.7, beta=0.3)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    \n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "    \n",
    "    # 7. í›ˆë ¨ ê¸°ë¡ì„ ìœ„í•œ ë³€ìˆ˜ë“¤\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    best_val_iou = 0.0\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"\\nğŸ¯ í›ˆë ¨ ì‹œì‘!\")\n",
    "    print(f\"  ì´ ì—í¬í¬: {NUM_EPOCHS}\")\n",
    "    print(f\"  í•™ìŠµë¥ : {LEARNING_RATE}\")\n",
    "    print(f\"  Early Stopping ê¸°ì¤€: {PATIENCE} ì—í¬í¬\")\n",
    "    \n",
    "    # 8. í›ˆë ¨ ë£¨í”„\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # í›ˆë ¨\n",
    "        train_metrics = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # ê²€ì¦\n",
    "        val_metrics = validate_epoch(model, val_loader, criterion, device, epoch)\n",
    "        \n",
    "        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # í•™ìŠµë¥  ë³€ê²½ ê°ì§€ ë° ì¶œë ¥\n",
    "        if new_lr < old_lr:\n",
    "            print(f\"  ğŸ“‰ í•™ìŠµë¥  ê°ì†Œ: {old_lr:.2e} â†’ {new_lr:.2e}\")\n",
    "        \n",
    "        # ê¸°ë¡ ì €ì¥\n",
    "        train_history.append(train_metrics)\n",
    "        val_history.append(val_metrics)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"\\nğŸ“Š Epoch {epoch}/{NUM_EPOCHS} ê²°ê³¼ (ì†Œìš”ì‹œê°„: {epoch_time:.2f}ì´ˆ)\")\n",
    "        print(f\"  Train - Loss: {train_metrics['loss']:.4f}, IoU: {train_metrics['iou']:.4f}, \"\n",
    "              f\"Dice: {train_metrics['dice_score']:.4f}, PixelAcc: {train_metrics['pixel_accuracy']:.4f}\")\n",
    "        print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, IoU: {val_metrics['iou']:.4f}, \"\n",
    "              f\"Dice: {val_metrics['dice_score']:.4f}, PixelAcc: {val_metrics['pixel_accuracy']:.4f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "        if val_metrics['iou'] > best_val_iou:\n",
    "            best_val_iou = val_metrics['iou']\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # ëª¨ë¸ ì €ì¥\n",
    "            if isinstance(model, DataParallel):\n",
    "                model_state = model.module.state_dict()\n",
    "            else:\n",
    "                model_state = model.state_dict()\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model_state,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_iou': val_metrics['iou'],\n",
    "                'val_dice': val_metrics['dice_score'],\n",
    "                'train_history': train_history,\n",
    "                'val_history': val_history\n",
    "            }, 'best_segformer_robot_arm.pth')\n",
    "            \n",
    "            print(f\"  ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! IoU: {best_val_iou:.4f} (Epoch {epoch})\")\n",
    "            \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  â³ ì„±ëŠ¥ ê°œì„  ì—†ìŒ ({patience_counter}/{PATIENCE})\")\n",
    "        \n",
    "        # Early Stopping\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"\\nğŸ›‘ Early Stopping! ìµœê³  ì„±ëŠ¥: IoU {best_val_iou:.4f} (Epoch {best_epoch})\")\n",
    "            break\n",
    "        \n",
    "        # ë§¤ 5 ì—í¬í¬ë§ˆë‹¤ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"\\nğŸ–¼ï¸ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” (Epoch {epoch})\")\n",
    "            visualize_predictions(model, val_loader, device, num_samples=3)\n",
    "    \n",
    "    # 9. í›ˆë ¨ ì™„ë£Œ í›„ ìµœì¢… ê²°ê³¼\n",
    "    print(f\"\\nğŸŠ í›ˆë ¨ ì™„ë£Œ!\")\n",
    "    print(f\"  ìµœê³  ì„±ëŠ¥: IoU {best_val_iou:.4f} (Epoch {best_epoch})\")\n",
    "    print(f\"  ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: best_segformer_robot_arm.pth\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # 11. ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "    print(f\"\\nğŸ–¼ï¸ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼\")\n",
    "    visualize_predictions(model, val_loader, device, num_samples=5)\n",
    "    \n",
    "    # 12. ì„±ëŠ¥ ì§€í‘œ ìš”ì•½\n",
    "    # print_final_metrics(val_history, best_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ë©”ì¸ í›ˆë ¨ ì‹¤í–‰\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0dbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ê°„ë‹¨í•œ SegFormer ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì½”ë“œ\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_best_model(checkpoint_path, device):\n",
    "    \"\"\"ì €ì¥ëœ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    print(f\"ğŸ“‚ ëª¨ë¸ ë¡œë”©: {checkpoint_path}\")\n",
    "    \n",
    "    # ëª¨ë¸ ìƒì„± (ê¸°ì¡´ í´ë˜ìŠ¤ ì‚¬ìš©)\n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "    \n",
    "    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Epoch {checkpoint['epoch']}, IoU: {checkpoint['val_iou']:.4f})\")\n",
    "    return model, checkpoint\n",
    "\n",
    "def calculate_metrics(pred_masks, true_masks):\n",
    "    \"\"\"ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    # ì „ì²´ í”½ì…€ ì •í™•ë„\n",
    "    pixel_acc = (pred_masks == true_masks).float().mean()\n",
    "    \n",
    "    # í´ë˜ìŠ¤ë³„ IoU ê³„ì‚°\n",
    "    ious = []\n",
    "    dices = []\n",
    "    \n",
    "    for cls in range(2):  # ë°°ê²½(0), ë¡œë´‡íŒ”(1)\n",
    "        pred_cls = (pred_masks == cls)\n",
    "        true_cls = (true_masks == cls)\n",
    "        \n",
    "        # IoU\n",
    "        intersection = (pred_cls & true_cls).sum().float()\n",
    "        union = (pred_cls | true_cls).sum().float()\n",
    "        iou = intersection / union if union > 0 else 1.0\n",
    "        \n",
    "        # Dice Score\n",
    "        dice = (2.0 * intersection) / (pred_cls.sum() + true_cls.sum()) if (pred_cls.sum() + true_cls.sum()) > 0 else 1.0\n",
    "        \n",
    "        ious.append(iou.item())\n",
    "        dices.append(dice.item())\n",
    "    \n",
    "    return {\n",
    "        'pixel_accuracy': pixel_acc.item(),\n",
    "        'background_iou': ious[0],\n",
    "        'robot_arm_iou': ious[1],\n",
    "        'mean_iou': np.mean(ious),\n",
    "        'background_dice': dices[0],\n",
    "        'robot_arm_dice': dices[1],\n",
    "        'mean_dice': np.mean(dices)\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "    print(\"\\nğŸ” ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_metrics = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"í‰ê°€ ì¤‘\"):\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            # ì˜ˆì¸¡\n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "            metrics = calculate_metrics(pred_masks, masks)\n",
    "            all_metrics.append(metrics)\n",
    "    \n",
    "    # ì „ì²´ í‰ê·  ê³„ì‚°\n",
    "    avg_metrics = {}\n",
    "    for key in all_metrics[0].keys():\n",
    "        avg_metrics[key] = np.mean([m[key] for m in all_metrics])\n",
    "        avg_metrics[key + '_std'] = np.std([m[key] for m in all_metrics])\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "def visualize_sample_predictions(model, val_loader, device, num_samples=3):\n",
    "    \"\"\"ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        # ImageNet ì •ê·œí™” ì—­ë³€í™˜\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        return torch.clamp(tensor * std + mean, 0, 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ì‹œê°í™”\n",
    "            image = denormalize(images[0].cpu()).permute(1, 2, 0).numpy()\n",
    "            true_mask = masks[0].cpu().numpy()\n",
    "            pred_mask = pred_masks[0].cpu().numpy()\n",
    "            \n",
    "            # IoU ê³„ì‚°\n",
    "            pred_robot = (pred_mask == 1)\n",
    "            true_robot = (true_mask == 1)\n",
    "            intersection = np.logical_and(pred_robot, true_robot).sum()\n",
    "            union = np.logical_or(pred_robot, true_robot).sum()\n",
    "            iou = intersection / union if union > 0 else 1.0\n",
    "            \n",
    "            # ì‹œê°í™”\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(true_mask, cmap='gray')\n",
    "            axes[i, 1].set_title('Ground Truth')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(pred_mask, cmap='gray')\n",
    "            axes[i, 2].set_title(f'Prediction (IoU: {iou:.3f})')\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('evaluation_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def print_evaluation_results(metrics):\n",
    "    \"\"\"í‰ê°€ ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "    print(\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"ğŸ¯ ì „ì²´ ì„±ëŠ¥:\")\n",
    "    print(f\"  Pixel Accuracy: {metrics['pixel_accuracy']:.4f} Â± {metrics['pixel_accuracy_std']:.4f}\")\n",
    "    print(f\"  Mean IoU: {metrics['mean_iou']:.4f} Â± {metrics['mean_iou_std']:.4f}\")\n",
    "    print(f\"  Mean Dice: {metrics['mean_dice']:.4f} Â± {metrics['mean_dice_std']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\")\n",
    "    print(f\"  ë°°ê²½ (Background):\")\n",
    "    print(f\"    IoU: {metrics['background_iou']:.4f} Â± {metrics['background_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['background_dice']:.4f} Â± {metrics['background_dice_std']:.4f}\")\n",
    "    \n",
    "    print(f\"  ë¡œë´‡íŒ” (Robot Arm):\")\n",
    "    print(f\"    IoU: {metrics['robot_arm_iou']:.4f} Â± {metrics['robot_arm_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['robot_arm_dice']:.4f} Â± {metrics['robot_arm_dice_std']:.4f}\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ë“±ê¸‰\n",
    "    robot_iou = metrics['robot_arm_iou']\n",
    "    if robot_iou >= 0.95:\n",
    "        grade = \"ğŸ¥‡ Excellent\"\n",
    "    elif robot_iou >= 0.90:\n",
    "        grade = \"ğŸ¥ˆ Very Good\"\n",
    "    elif robot_iou >= 0.85:\n",
    "        grade = \"ğŸ¥‰ Good\"\n",
    "    elif robot_iou >= 0.80:\n",
    "        grade = \"âœ… Acceptable\"\n",
    "    else:\n",
    "        grade = \"âš ï¸ Needs Improvement\"\n",
    "    \n",
    "    print(f\"\\nğŸ–ï¸ ë¡œë´‡íŒ” ì„±ëŠ¥ ë“±ê¸‰: {grade}\")\n",
    "\n",
    "def run_simple_evaluation():\n",
    "    \"\"\"ê°„ë‹¨í•œ í‰ê°€ ì‹¤í–‰\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint_path = 'best_segformer_robot_arm.pth'\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë” ìƒì„± (ê¸°ì¡´ í›ˆë ¨ ì½”ë“œì™€ ë™ì¼)\n",
    "    print(\"ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "    \n",
    "    # ê¸°ì¡´ í›ˆë ¨ ì½”ë“œì—ì„œ ì‚¬ìš©í•œ í•¨ìˆ˜ë“¤ (import í•„ìš”)\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    \n",
    "    # ë°ì´í„° ë§¤ì¹­ (ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "    \n",
    "    # ì‹œì  ì •ë³´ ì¶”ì¶œ\n",
    "    views = []\n",
    "    for img_path in image_paths:\n",
    "        if 'left' in img_path:\n",
    "            views.append('left')\n",
    "        elif 'right' in img_path:\n",
    "            views.append('right')\n",
    "        elif 'top' in img_path:\n",
    "            views.append('top')\n",
    "        else:\n",
    "            views.append('unknown')\n",
    "    \n",
    "    # Train/Validation ë¶„í•  (ê¸°ì¡´ê³¼ ë™ì¼í•œ ë°©ì‹)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "        image_paths, mask_paths,\n",
    "        test_size=0.2,\n",
    "        random_state=42,  # ë™ì¼í•œ ë¶„í•  ë³´ì¥\n",
    "        stratify=views\n",
    "    )\n",
    "    \n",
    "    # Validation ë°ì´í„°ì…‹ ìƒì„±\n",
    "    val_transforms = get_val_transforms(512)  # ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©\n",
    "    val_dataset = RobotArmDataset(\n",
    "        val_img_paths, val_mask_paths, \n",
    "        transform=val_transforms, \n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # Validation ë°ì´í„°ë¡œë” ìƒì„±\n",
    "    from torch.utils.data import DataLoader\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=8, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"ê²€ì¦ ë°ì´í„°: {len(val_img_paths)}ê°œ\")\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, checkpoint = load_best_model(checkpoint_path, device)\n",
    "    \n",
    "    # ì„±ëŠ¥ í‰ê°€\n",
    "    metrics = evaluate_model(model, val_loader, device)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print_evaluation_results(metrics)\n",
    "    \n",
    "    # ìƒ˜í”Œ ì‹œê°í™”\n",
    "    print(f\"\\nğŸ–¼ï¸ ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\")\n",
    "    visualize_sample_predictions(model, val_loader, device, num_samples=3)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ë°©ë²• 1: ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ (ë°ì´í„° ë¡œë” ìƒˆë¡œ ìƒì„±)\n",
    "if __name__ == \"__main__\":\n",
    "    # í•„ìš”í•œ í•¨ìˆ˜ë“¤ì´ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "    # match_image_mask_pairs, get_val_transforms, RobotArmDataset ë“±\n",
    "    \n",
    "    metrics = run_simple_evaluation()\n",
    "    print(f\"\\nğŸŠ í‰ê°€ ì™„ë£Œ!\")\n",
    "    print(f\"ê²°ê³¼ ì´ë¯¸ì§€: evaluation_samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f476c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_best_model(checkpoint_path, device):\n",
    "    \"\"\"ì €ì¥ëœ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    print(f\"ğŸ“‚ ëª¨ë¸ ë¡œë”©: {checkpoint_path}\")\n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Epoch {checkpoint['epoch']}, IoU: {checkpoint['val_iou']:.4f})\")\n",
    "    return model, checkpoint\n",
    "\n",
    "def calculate_metrics(pred_masks, true_masks):\n",
    "    \"\"\"ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    pixel_acc = (pred_masks == true_masks).float().mean()\n",
    "    ious, dices = [], []\n",
    "    for cls in range(2):\n",
    "        pred_cls = (pred_masks == cls)\n",
    "        true_cls = (true_masks == cls)\n",
    "        intersection = (pred_cls & true_cls).sum().float()\n",
    "        union = (pred_cls | true_cls).sum().float()\n",
    "        iou = intersection / union if union > 0 else 1.0\n",
    "        dice = (2.0 * intersection) / (pred_cls.sum() + true_cls.sum()) if (pred_cls.sum() + true_cls.sum()) > 0 else 1.0\n",
    "        ious.append(iou.item())\n",
    "        dices.append(dice.item())\n",
    "    return {\n",
    "        'pixel_accuracy': pixel_acc.item(),\n",
    "        'background_iou': ious[0],\n",
    "        'robot_arm_iou': ious[1],\n",
    "        'mean_iou': np.mean(ious),\n",
    "        'background_dice': dices[0],\n",
    "        'robot_arm_dice': dices[1],\n",
    "        'mean_dice': np.mean(dices)\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "    print(\"\\nğŸ” ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘...\")\n",
    "    model.eval()\n",
    "    all_metrics = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"í‰ê°€ ì¤‘\"):\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            metrics = calculate_metrics(pred_masks, masks)\n",
    "            all_metrics.append(metrics)\n",
    "    avg_metrics = {}\n",
    "    for key in all_metrics[0].keys():\n",
    "        avg_metrics[key] = np.mean([m[key] for m in all_metrics])\n",
    "        avg_metrics[key + '_std'] = np.std([m[key] for m in all_metrics])\n",
    "    return avg_metrics\n",
    "\n",
    "def print_evaluation_results(metrics):\n",
    "    print(\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ¯ ì „ì²´ ì„±ëŠ¥:\")\n",
    "    print(f\"  Pixel Accuracy: {metrics['pixel_accuracy']:.4f} Â± {metrics['pixel_accuracy_std']:.4f}\")\n",
    "    print(f\"  Mean IoU: {metrics['mean_iou']:.4f} Â± {metrics['mean_iou_std']:.4f}\")\n",
    "    print(f\"  Mean Dice: {metrics['mean_dice']:.4f} Â± {metrics['mean_dice_std']:.4f}\")\n",
    "    print(f\"\\nğŸ“‹ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\")\n",
    "    print(f\"  ë°°ê²½ (Background):\")\n",
    "    print(f\"    IoU: {metrics['background_iou']:.4f} Â± {metrics['background_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['background_dice']:.4f} Â± {metrics['background_dice_std']:.4f}\")\n",
    "    print(f\"  ë¡œë´‡íŒ” (Robot Arm):\")\n",
    "    print(f\"    IoU: {metrics['robot_arm_iou']:.4f} Â± {metrics['robot_arm_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['robot_arm_dice']:.4f} Â± {metrics['robot_arm_dice_std']:.4f}\")\n",
    "    robot_iou = metrics['robot_arm_iou']\n",
    "    if robot_iou >= 0.95:\n",
    "        grade = \"ğŸ¥‡ Excellent\"\n",
    "    elif robot_iou >= 0.90:\n",
    "        grade = \"ğŸ¥ˆ Very Good\"\n",
    "    elif robot_iou >= 0.85:\n",
    "        grade = \"ğŸ¥‰ Good\"\n",
    "    elif robot_iou >= 0.80:\n",
    "        grade = \"âœ… Acceptable\"\n",
    "    else:\n",
    "        grade = \"âš ï¸ Needs Improvement\"\n",
    "    print(f\"\\nğŸ–ï¸ ë¡œë´‡íŒ” ì„±ëŠ¥ ë“±ê¸‰: {grade}\")\n",
    "\n",
    "def plot_key_metrics(metrics):\n",
    "    \"\"\"í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ ì‹œê°í™”\"\"\"\n",
    "    keys = ['mean_iou', 'mean_dice', 'pixel_accuracy']\n",
    "    labels = ['Mean IoU', 'Mean Dice', 'Pixel Accuracy']\n",
    "    values = [metrics[k] for k in keys]\n",
    "    stds = [metrics[k + '_std'] for k in keys]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(labels, values, yerr=stds, capsize=5, color='skyblue')\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f\"{value:.3f}\",\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('SegFormer Evaluation Metrics')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metric_bar_chart.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "def run_simple_evaluation():\n",
    "    \"\"\"ê°„ë‹¨í•œ í‰ê°€ ì‹¤í–‰\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint_path = 'best_segformer_robot_arm.pth'\n",
    "\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "\n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "\n",
    "    views = []\n",
    "    for img_path in image_paths:\n",
    "        if 'left' in img_path:\n",
    "            views.append('left')\n",
    "        elif 'right' in img_path:\n",
    "            views.append('right')\n",
    "        elif 'top' in img_path:\n",
    "            views.append('top')\n",
    "        else:\n",
    "            views.append('unknown')\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "        image_paths, mask_paths,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=views\n",
    "    )\n",
    "\n",
    "    val_transforms = get_val_transforms(512)\n",
    "    val_dataset = RobotArmDataset(val_img_paths, val_mask_paths, transform=val_transforms, is_train=False)\n",
    "    from torch.utils.data import DataLoader\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    print(f\"ê²€ì¦ ë°ì´í„°: {len(val_img_paths)}ê°œ\")\n",
    "\n",
    "    model, checkpoint = load_best_model(checkpoint_path, device)\n",
    "    metrics = evaluate_model(model, val_loader, device)\n",
    "    print_evaluation_results(metrics)\n",
    "    plot_key_metrics(metrics)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    metrics = run_simple_evaluation()\n",
    "    print(f\"\\nğŸŠ í‰ê°€ ì™„ë£Œ! ì‹œê°í™” ì €ì¥ë¨: metric_bar_chart.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ëœë¤ ìƒ˜í”Œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™”\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_test_transforms(image_size=512):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ì „ì²˜ë¦¬ (ì •ê·œí™”ë§Œ)\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def load_model_for_test(checkpoint_path, device):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    print(f\"ğŸ“‚ ëª¨ë¸ ë¡œë”©: {checkpoint_path}\")\n",
    "    \n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Epoch {checkpoint['epoch']}, IoU: {checkpoint['val_iou']:.4f})\")\n",
    "    return model\n",
    "\n",
    "def predict_single_image(model, image_path, mask_path, transform, device):\n",
    "    \"\"\"ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡\"\"\"\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    original_image = image.copy()\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    \n",
    "    # ë§ˆìŠ¤í¬ ë¡œë“œ (ì •ë‹µ)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = (mask > 127).astype(np.uint8)\n",
    "    original_mask = mask.copy()\n",
    "    \n",
    "    # ì „ì²˜ë¦¬ (ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ëª¨ë‘ 512x512ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)\n",
    "    transformed = transform(image=image, mask=mask)\n",
    "    image_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "    resized_mask = transformed['mask']  # 512x512ë¡œ ë¦¬ì‚¬ì´ì¦ˆëœ ë§ˆìŠ¤í¬\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        pred_mask = torch.argmax(output, dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë‹¤ì‹œ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    pred_mask_resized = cv2.resize(\n",
    "        pred_mask.astype(np.uint8), \n",
    "        (original_width, original_height), \n",
    "        interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "    \n",
    "    # IoU ê³„ì‚° (ì›ë³¸ í¬ê¸°ì—ì„œ)\n",
    "    pred_robot = (pred_mask_resized == 1)\n",
    "    true_robot = (original_mask == 1)\n",
    "    intersection = np.logical_and(pred_robot, true_robot).sum()\n",
    "    union = np.logical_or(pred_robot, true_robot).sum()\n",
    "    iou = intersection / union if union > 0 else 1.0\n",
    "    \n",
    "    # Dice Score ê³„ì‚° (ì›ë³¸ í¬ê¸°ì—ì„œ)\n",
    "    dice = (2.0 * intersection) / (pred_robot.sum() + true_robot.sum()) if (pred_robot.sum() + true_robot.sum()) > 0 else 1.0\n",
    "    \n",
    "    return {\n",
    "        'original_image': original_image,\n",
    "        'true_mask': original_mask,\n",
    "        'pred_mask': pred_mask_resized,  # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›ëœ ì˜ˆì¸¡ ë§ˆìŠ¤í¬\n",
    "        'pred_mask_512': pred_mask,      # 512x512 ì˜ˆì¸¡ ë§ˆìŠ¤í¬ (ì‹œê°í™”ìš©)\n",
    "        'iou': iou,\n",
    "        'dice': dice,\n",
    "        'image_path': image_path,\n",
    "        'mask_path': mask_path,\n",
    "        'original_size': (original_height, original_width)\n",
    "    }\n",
    "\n",
    "def random_sample_test(model, image_paths, mask_paths, num_samples=10, device='cuda'):\n",
    "    \"\"\"ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"ğŸ² ëœë¤ ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({num_samples}ê°œ ìƒ˜í”Œ)\")\n",
    "    \n",
    "    # ëœë¤ ì¸ë±ìŠ¤ ì„ íƒ\n",
    "    total_samples = len(image_paths)\n",
    "    random_indices = random.sample(range(total_samples), min(num_samples, total_samples))\n",
    "    \n",
    "    transform = get_test_transforms()\n",
    "    results = []\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        print(f\"  ì²˜ë¦¬ ì¤‘: {i+1}/{len(random_indices)} - {Path(image_paths[idx]).name}\")\n",
    "        \n",
    "        result = predict_single_image(\n",
    "            model, \n",
    "            image_paths[idx], \n",
    "            mask_paths[idx], \n",
    "            transform, \n",
    "            device\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_test_results(results, save_path='test_results.png'):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    num_samples = len(results)\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        original_image = result['original_image']\n",
    "        true_mask = result['true_mask']\n",
    "        pred_mask = result['pred_mask']  # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›ëœ ë§ˆìŠ¤í¬\n",
    "        iou = result['iou']\n",
    "        dice = result['dice']\n",
    "        original_size = result['original_size']\n",
    "        \n",
    "        # ì›ë³¸ ì´ë¯¸ì§€\n",
    "        axes[i, 0].imshow(original_image)\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}\\n{Path(result[\"image_path\"]).name}\\nSize: {original_size[1]}x{original_size[0]}', fontsize=9)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # ì‹¤ì œ ë§ˆìŠ¤í¬\n",
    "        axes[i, 1].imshow(true_mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth Mask', fontsize=10)\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # ì˜ˆì¸¡ ë§ˆìŠ¤í¬ (ì›ë³¸ í¬ê¸°)\n",
    "        axes[i, 2].imshow(pred_mask, cmap='gray')\n",
    "        axes[i, 2].set_title(f'Predicted Mask\\nIoU: {iou:.3f}, Dice: {dice:.3f}', fontsize=10)\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}\")\n",
    "\n",
    "def visualize_test_results_comparison(results, save_path='test_comparison.png'):\n",
    "    \"\"\"ì›ë³¸ í¬ê¸° vs 512x512 ë¹„êµ ì‹œê°í™”\"\"\"\n",
    "    num_samples = min(len(results), 3)  # ìµœëŒ€ 3ê°œë§Œ ë¹„êµ\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5*num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        result = results[i]\n",
    "        original_image = result['original_image']\n",
    "        true_mask = result['true_mask']\n",
    "        pred_mask_original = result['pred_mask']  # ì›ë³¸ í¬ê¸°\n",
    "        pred_mask_512 = result['pred_mask_512']   # 512x512\n",
    "        iou = result['iou']\n",
    "        \n",
    "        # ì›ë³¸ ì´ë¯¸ì§€\n",
    "        axes[i, 0].imshow(original_image)\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}', fontsize=10)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # ì‹¤ì œ ë§ˆìŠ¤í¬\n",
    "        axes[i, 1].imshow(true_mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth', fontsize=10)\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # ì˜ˆì¸¡ ë§ˆìŠ¤í¬ (512x512)\n",
    "        axes[i, 2].imshow(pred_mask_512, cmap='gray')\n",
    "        axes[i, 2].set_title('Prediction (512x512)', fontsize=10)\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # ì˜ˆì¸¡ ë§ˆìŠ¤í¬ (ì›ë³¸ í¬ê¸°)\n",
    "        axes[i, 3].imshow(pred_mask_original, cmap='gray')\n",
    "        axes[i, 3].set_title(f'Prediction (Original)\\nIoU: {iou:.3f}', fontsize=10)\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ğŸ’¾ ë¹„êµ ê²°ê³¼ ì €ì¥: {save_path}\")\n",
    "\n",
    "def print_test_summary(results):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥\"\"\"\n",
    "    ious = [r['iou'] for r in results]\n",
    "    dices = [r['dice'] for r in results]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ({len(results)}ê°œ ìƒ˜í”Œ)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"IoU Score:\")\n",
    "    print(f\"  í‰ê· : {np.mean(ious):.4f}\")\n",
    "    print(f\"  í‘œì¤€í¸ì°¨: {np.std(ious):.4f}\")\n",
    "    print(f\"  ìµœì†Œ: {np.min(ious):.4f}\")\n",
    "    print(f\"  ìµœëŒ€: {np.max(ious):.4f}\")\n",
    "    \n",
    "    print(f\"\\nDice Score:\")\n",
    "    print(f\"  í‰ê· : {np.mean(dices):.4f}\")\n",
    "    print(f\"  í‘œì¤€í¸ì°¨: {np.std(dices):.4f}\")\n",
    "    print(f\"  ìµœì†Œ: {np.min(dices):.4f}\")\n",
    "    print(f\"  ìµœëŒ€: {np.max(dices):.4f}\")\n",
    "    \n",
    "    # ì„±ëŠ¥ë³„ ë¶„ë¥˜\n",
    "    excellent = sum(1 for iou in ious if iou >= 0.95)\n",
    "    good = sum(1 for iou in ious if 0.9 <= iou < 0.95)\n",
    "    acceptable = sum(1 for iou in ious if 0.8 <= iou < 0.9)\n",
    "    poor = sum(1 for iou in ious if iou < 0.8)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì„±ëŠ¥ ë¶„í¬:\")\n",
    "    print(f\"  Excellent (IoU â‰¥ 0.95): {excellent}ê°œ ({excellent/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Good (0.9 â‰¤ IoU < 0.95): {good}ê°œ ({good/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Acceptable (0.8 â‰¤ IoU < 0.9): {acceptable}ê°œ ({acceptable/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Poor (IoU < 0.8): {poor}ê°œ ({poor/len(results)*100:.1f}%)\")\n",
    "\n",
    "def analyze_by_view(results):\n",
    "    \"\"\"ì‹œì ë³„ ì„±ëŠ¥ ë¶„ì„\"\"\"\n",
    "    view_results = {'left': [], 'right': [], 'top': [], 'unknown': []}\n",
    "    \n",
    "    for result in results:\n",
    "        path = result['image_path']\n",
    "        if 'left' in path:\n",
    "            view = 'left'\n",
    "        elif 'right' in path:\n",
    "            view = 'right'\n",
    "        elif 'top' in path:\n",
    "            view = 'top'\n",
    "        else:\n",
    "            view = 'unknown'\n",
    "        \n",
    "        view_results[view].append(result['iou'])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì‹œì ë³„ ì„±ëŠ¥ ë¶„ì„:\")\n",
    "    print(\"-\"*40)\n",
    "    for view, ious in view_results.items():\n",
    "        if ious:\n",
    "            print(f\"{view.upper()}: {len(ious)}ê°œ - í‰ê·  IoU {np.mean(ious):.4f}\")\n",
    "\n",
    "def run_random_test(num_samples=10):\n",
    "    \"\"\"ëœë¤ í…ŒìŠ¤íŠ¸ ë©”ì¸ í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸš€ ëœë¤ ìƒ˜í”Œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 1. ë°ì´í„° ê²½ë¡œ ìˆ˜ì§‘\n",
    "    print(\"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    \n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "    \n",
    "    print(f\"ì´ {len(image_paths)}ê°œ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ ë°œê²¬\")\n",
    "    \n",
    "    # 2. ëª¨ë¸ ë¡œë“œ\n",
    "    model = load_model_for_test('best_segformer_robot_arm.pth', device)\n",
    "    \n",
    "    # 3. ëœë¤ ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸\n",
    "    results = random_sample_test(model, image_paths, mask_paths, num_samples, device)\n",
    "    \n",
    "    # 4. ê²°ê³¼ ì‹œê°í™”\n",
    "    print(f\"\\nğŸ–¼ï¸ ê²°ê³¼ ì‹œê°í™” ì¤‘...\")\n",
    "    visualize_test_results(results, f'random_test_{num_samples}_samples.png')\n",
    "    \n",
    "    # 4-1. ì¶”ê°€: í¬ê¸° ë¹„êµ ì‹œê°í™” (ì²˜ìŒ 3ê°œ ìƒ˜í”Œ)\n",
    "    if len(results) >= 3:\n",
    "        print(f\"ğŸ” í¬ê¸° ë¹„êµ ì‹œê°í™” ì¤‘...\")\n",
    "        visualize_test_results_comparison(results[:3], f'size_comparison_{num_samples}_samples.png')\n",
    "    \n",
    "    # 5. ê²°ê³¼ ë¶„ì„\n",
    "    print_test_summary(results)\n",
    "    analyze_by_view(results)\n",
    "    \n",
    "    print(f\"\\nğŸŠ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===============================\n",
    "# íŠ¹ì • ì‹œì ë§Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜\n",
    "# ===============================\n",
    "\n",
    "def test_specific_view(view='left', num_samples=5):\n",
    "    \"\"\"íŠ¹ì • ì‹œì ë§Œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"ğŸ¯ {view.upper()} ì‹œì  ì „ìš© í…ŒìŠ¤íŠ¸\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # ë°ì´í„° ìˆ˜ì§‘\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    image_paths, mask_paths = match_image_mask_pairs(original_images_root, mask_images_root)\n",
    "    \n",
    "    # íŠ¹ì • ì‹œì ë§Œ í•„í„°ë§\n",
    "    view_image_paths = []\n",
    "    view_mask_paths = []\n",
    "    \n",
    "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "        if view in img_path:\n",
    "            view_image_paths.append(img_path)\n",
    "            view_mask_paths.append(mask_path)\n",
    "    \n",
    "    print(f\"{view.upper()} ì‹œì  ë°ì´í„°: {len(view_image_paths)}ê°œ\")\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸\n",
    "    model = load_model_for_test('best_segformer_robot_arm.pth', device)\n",
    "    results = random_sample_test(model, view_image_paths, view_mask_paths, num_samples, device)\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    visualize_test_results(results, f'{view}_view_test.png')\n",
    "    print_test_summary(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===============================\n",
    "# ì‹¤í–‰ ë¶€ë¶„\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ëœë¤ 10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸\n",
    "    results = run_random_test(num_samples=10)\n",
    "    \n",
    "    # ë˜ëŠ” íŠ¹ì • ì‹œì ë§Œ í…ŒìŠ¤íŠ¸\n",
    "    # left_results = test_specific_view('left', num_samples=5)\n",
    "    # right_results = test_specific_view('right', num_samples=5)\n",
    "    # top_results = test_specific_view('top', num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a3ab0",
   "metadata": {},
   "source": [
    "ì›ë³¸ì´ë¯¸ì§€ì— ë§ˆìŠ¤í¬ ì±„ìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4138c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ===============================\n",
    "# SegFormer ëª¨ë¸ ì •ì˜\n",
    "# ===============================\n",
    "\n",
    "class SegFormerForRobotArm(nn.Module):\n",
    "    def __init__(self, num_classes=2, model_name=\"nvidia/mit-b2\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # SegFormer ëª¨ë¸ ë¡œë“œ (pretrained MiT ë°±ë³¸ í¬í•¨)\n",
    "        # model_name ì˜µì…˜:\n",
    "        # - nvidia/mit-b0: 3.7M params (ë¹ ë¦„, ê°€ë²¼ì›€)\n",
    "        # - nvidia/mit-b1: 14M params  \n",
    "        # - nvidia/mit-b2: 25M params (ê¶Œì¥, ê· í˜•ì )\n",
    "        # - nvidia/mit-b3: 45M params (ë” ë†’ì€ ì„±ëŠ¥)\n",
    "        # - nvidia/mit-b4: 62M params\n",
    "        # - nvidia/mit-b5: 82M params (ìµœê³  ì„±ëŠ¥, ëŠë¦¼)\n",
    "        \n",
    "        print(f\"ğŸ—ï¸ SegFormer ëª¨ë¸ ë¡œë”©: {model_name}\")\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥\n",
    "        total_params = sum(p.numel() for p in self.segformer.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.segformer.parameters() if p.requires_grad)\n",
    "        print(f\"ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {total_params:,}\")\n",
    "        print(f\"ğŸ“Š í›ˆë ¨ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}\")\n",
    "        \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.segformer(pixel_values=pixel_values)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # SegFormer ì¶œë ¥ì„ ì…ë ¥ í¬ê¸°ë¡œ ì—…ìƒ˜í”Œë§\n",
    "        # ì…ë ¥: [B, C, H, W] -> ì¶œë ¥: [B, num_classes, H, W]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=pixel_values.shape[-2:],  # (H, W)\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        return upsampled_logits\n",
    "\n",
    "model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def overlay_mask_on_image(image: np.ndarray, mask: np.ndarray, alpha=0.5, color=(0, 255, 0)):\n",
    "    \"\"\"ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— ì´ˆë¡ìƒ‰ ë§ˆìŠ¤í¬ë¥¼ ë§ì”Œì›€\"\"\"\n",
    "    color_mask = np.zeros_like(image)\n",
    "    color_mask[mask == 1] = color\n",
    "    blended = cv2.addWeighted(image, 1 - alpha, color_mask, alpha, 0)\n",
    "    return blended\n",
    "\n",
    "def get_val_transforms(image_size=512):\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "def visualize_from_saved_model(image_path, model_path='best_segformer_robot_arm.pth', model_size='nvidia/mit-b2', image_size=512):\n",
    "    # 1. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    orig_np = np.array(image)\n",
    "\n",
    "    # 2. ë³€í™˜ ì ìš©\n",
    "    transform = get_val_transforms(image_size)\n",
    "    transformed = transform(image=np.array(image))\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "\n",
    "    # 3. ëª¨ë¸ ë¡œë“œ\n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=model_size)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 4. ì¶”ë¡  ì‹œê°„ ì¸¡ì •\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        output = model(input_tensor)  # [1, C, H, W]\n",
    "        end = time.time()\n",
    "\n",
    "        pred_mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    print(f\"â±ï¸ ì¶”ë¡  ì‹œê°„: {(end - start)*1000:.2f} ms\")  # ë˜ëŠ” sec ë‹¨ìœ„ë¡œ ë³´ê¸° ì›í•˜ë©´ : .4f sec\n",
    "\n",
    "    # 5. ì‹œê°í™”\n",
    "    if orig_np.shape[:2] != pred_mask.shape:\n",
    "        pred_mask = cv2.resize(pred_mask, (orig_np.shape[1], orig_np.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    overlay = overlay_mask_on_image(orig_np, pred_mask, alpha=0.5, color=(0, 255, 0))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"SegFormer result\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ì˜ˆì‹œ ì‚¬ìš©\n",
    "image_path = \"/home/ibom002/dataset/Fr5_intertek_4th_250526/left/zed_38007749_left_1748249115.548.jpg\"\n",
    "visualize_from_saved_model(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c655451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
