{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU 설정\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # GPU 0,1,2 사용\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e680b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 기존 코드 (데이터 매칭, 데이터셋, 변환)\n",
    "# ===============================\n",
    "\n",
    "def match_image_mask_pairs(original_root, mask_root):\n",
    "    \"\"\"원본 이미지와 마스크 파일을 매칭\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"📊 데이터 매칭 및 수집\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"🔍 데이터 매칭 시작\")\n",
    "    print(f\"  원본 이미지: {original_root}\")\n",
    "    print(f\"  마스크 이미지: {mask_root}\")\n",
    "    \n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "    \n",
    "    original_root = Path(original_root)\n",
    "    mask_root = Path(mask_root)\n",
    "    \n",
    "    # 폴더 매핑 테이블\n",
    "    folder_mapping = {\n",
    "        'Fr5_intertek_1st_250526': '1st',\n",
    "        'Fr5_intertek_2nd_250526': '2nd', \n",
    "        'Fr5_intertek_3rd_250526': '3rd',\n",
    "        'Fr5_intertek_4th_250526': '4th',\n",
    "        'Fr5_intertek_5th_250526': '5th',\n",
    "        'Fr5_intertek_6th_250526': '6th',\n",
    "        'Fr5_intertek_7th_250526': '7th'\n",
    "    }\n",
    "    \n",
    "    total_pairs = 0\n",
    "    \n",
    "    for original_folder, mask_folder in folder_mapping.items():\n",
    "        original_folder_path = original_root / original_folder\n",
    "        mask_folder_path = mask_root / mask_folder\n",
    "        \n",
    "        if not original_folder_path.exists():\n",
    "            print(f\"⚠️  원본 폴더 없음: {original_folder_path}\")\n",
    "            continue\n",
    "            \n",
    "        if not mask_folder_path.exists():\n",
    "            print(f\"⚠️  마스크 폴더 없음: {mask_folder_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"📁 처리 중: {original_folder} → {mask_folder}\")\n",
    "        \n",
    "        # left, right, top 시점별 처리\n",
    "        for view in ['left', 'right', 'top']:\n",
    "            original_view_path = original_folder_path / view\n",
    "            mask_view_path = mask_folder_path / view / 'masks'\n",
    "            \n",
    "            if not original_view_path.exists():\n",
    "                print(f\"  ⚠️  원본 {view} 폴더 없음\")\n",
    "                continue\n",
    "                \n",
    "            if not mask_view_path.exists():\n",
    "                print(f\"  ⚠️  마스크 {view}/masks 폴더 없음: {mask_view_path}\")\n",
    "                continue\n",
    "            \n",
    "            view_pairs = 0\n",
    "            unmatched_samples = []\n",
    "            \n",
    "            # 원본 이미지들 찾기\n",
    "            for img_ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG']:\n",
    "                for original_img_path in original_view_path.glob(img_ext):\n",
    "                    # 마스크 파일명 패턴들 시도\n",
    "                    possible_mask_names = [\n",
    "                        f\"{original_img_path.stem}_mask.png\",\n",
    "                        f\"{original_img_path.stem}.png\",\n",
    "                        f\"{original_img_path.name.replace('.jpg', '_mask.png')}\",\n",
    "                        f\"{original_img_path.name.replace('.JPG', '_mask.png')}\",\n",
    "                        f\"{original_img_path.name.replace('.jpeg', '_mask.png')}\",\n",
    "                        f\"{original_img_path.name.replace('.JPEG', '_mask.png')}\"\n",
    "                    ]\n",
    "                    \n",
    "                    found = False\n",
    "                    for possible_name in possible_mask_names:\n",
    "                        possible_mask_path = mask_view_path / possible_name\n",
    "                        if possible_mask_path.exists():\n",
    "                            image_paths.append(str(original_img_path))\n",
    "                            mask_paths.append(str(possible_mask_path))\n",
    "                            view_pairs += 1\n",
    "                            found = True\n",
    "                            break\n",
    "                    \n",
    "                    if not found:\n",
    "                        unmatched_samples.append(original_img_path.name)\n",
    "            \n",
    "            if view_pairs > 0:\n",
    "                print(f\"  ✅ {view}: {view_pairs}개 매칭 쌍\")\n",
    "                total_pairs += view_pairs\n",
    "                \n",
    "                if unmatched_samples:\n",
    "                    print(f\"    ⚠️  매칭 실패 ({len(unmatched_samples)}개): {unmatched_samples[:3]}\")\n",
    "            else:\n",
    "                print(f\"  ❌ {view}: 매칭 실패\")\n",
    "    \n",
    "    print(f\"\\n🎉 총 {len(image_paths)}개의 이미지-마스크 쌍을 찾았습니다!\")\n",
    "    return image_paths, mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotArmDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None, is_train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 원본 RGB 이미지 로드\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"이미지 로드 실패: {image_path}\")\n",
    "            \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 마스크 이미지 로드\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if mask is None:\n",
    "            raise ValueError(f\"마스크 로드 실패: {mask_path}\")\n",
    "        \n",
    "        # 마스크를 이진화 (0: 배경, 1: 로봇팔)\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "        \n",
    "        # 변환 적용\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'mask': mask.long(),\n",
    "            'image_path': image_path,\n",
    "            'mask_path': mask_path\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms(image_size=512, augmentation_level='moderate'):\n",
    "    \"\"\"\n",
    "    데이터 증강 설정\n",
    "    augmentation_level: 'light', 'moderate', 'heavy'\n",
    "    \"\"\"\n",
    "    \n",
    "    if augmentation_level == 'light':\n",
    "        # 가벼운 증강 (빠른 훈련, 안정적)\n",
    "        return A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    elif augmentation_level == 'moderate':\n",
    "        # 중간 증강 (균형잡힌 성능, 권장)\n",
    "        return A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1, \n",
    "                scale_limit=0.1, \n",
    "                rotate_limit=15, \n",
    "                p=0.5\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2, \n",
    "                contrast_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=10, \n",
    "                sat_shift_limit=20, \n",
    "                val_shift_limit=10, \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=(10, 50), p=0.3),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    elif augmentation_level == 'heavy':\n",
    "        # 강한 증강 (로봇팔 특화, 더 robust한 모델)\n",
    "        return A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            \n",
    "            # 기하학적 변환 (로봇팔의 다양한 자세)\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.3),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Rotate(limit=30, p=0.5),  # 더 큰 회전각\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.15, \n",
    "                scale_limit=0.15, \n",
    "                rotate_limit=20, \n",
    "                p=0.6\n",
    "            ),\n",
    "            \n",
    "            # 색상/조명 변환 (다양한 환경 조건)\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.3, \n",
    "                contrast_limit=0.3, \n",
    "                p=0.6\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=15, \n",
    "                sat_shift_limit=30, \n",
    "                val_shift_limit=15, \n",
    "                p=0.4\n",
    "            ),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "            A.CLAHE(clip_limit=2.0, p=0.3),  # 대비 개선\n",
    "            \n",
    "            # 노이즈 및 블러 (카메라 품질 시뮬레이션)\n",
    "            A.GaussNoise(var_limit=(10, 80), p=0.4),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.2),\n",
    "            A.MotionBlur(blur_limit=3, p=0.2),\n",
    "            \n",
    "            # 가려짐 시뮬레이션 (실제 환경의 장애물)\n",
    "            A.CoarseDropout(\n",
    "                max_holes=3, \n",
    "                max_height=32, \n",
    "                max_width=32, \n",
    "                min_holes=1, \n",
    "                min_height=8, \n",
    "                min_width=8, \n",
    "                p=0.3\n",
    "            ),\n",
    "            \n",
    "            # 그림자 효과 (조명 변화) - 일부 버전에서 지원하지 않을 수 있음\n",
    "            # A.RandomShadow(\n",
    "            #     shadow_roi=(0, 0.5, 1, 1),\n",
    "            #     num_shadows_lower=1,\n",
    "            #     num_shadows_upper=2,\n",
    "            #     shadow_dimension=5,\n",
    "            #     p=0.3\n",
    "            # ),\n",
    "            \n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"augmentation_level must be 'light', 'moderate', or 'heavy'\")\n",
    "\n",
    "def get_val_transforms(image_size=512):\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def debug_tensor_shapes(images, masks, outputs, step_name=\"\"):\n",
    "    \"\"\"텐서 크기 디버깅용 함수\"\"\"\n",
    "    print(f\"\\n🔍 {step_name} 텐서 크기:\")\n",
    "    print(f\"  입력 이미지: {images.shape}\")\n",
    "    print(f\"  타겟 마스크: {masks.shape}\")\n",
    "    print(f\"  모델 출력: {outputs.shape}\")\n",
    "    \n",
    "    if images.shape[-2:] != outputs.shape[-2:]:\n",
    "        print(f\"  ⚠️ 크기 불일치 감지!\")\n",
    "        print(f\"    입력 크기: {images.shape[-2:]}\")\n",
    "        print(f\"    출력 크기: {outputs.shape[-2:]}\")\n",
    "    else:\n",
    "        print(f\"  ✅ 크기 일치 확인\")\n",
    "    \"\"\"데이터 품질 검증\"\"\"\n",
    "    print(f\"\\n🔍 데이터 품질 검증 (샘플 {num_samples}개)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for i in range(min(num_samples, len(image_paths))):\n",
    "        img_path = image_paths[i]\n",
    "        mask_path = mask_paths[i]\n",
    "        \n",
    "        print(f\"\\n📋 샘플 {i+1}:\")\n",
    "        print(f\"  원본: {Path(img_path).name}\")\n",
    "        print(f\"  마스크: {Path(mask_path).name}\")\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"  ❌ 원본 이미지 로드 실패\")\n",
    "                continue\n",
    "                \n",
    "            if mask is None:\n",
    "                print(f\"  ❌ 마스크 이미지 로드 실패\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  📏 원본 크기: {img.shape}\")\n",
    "            print(f\"  📏 마스크 크기: {mask.shape}\")\n",
    "            \n",
    "            unique_values = np.unique(mask)\n",
    "            print(f\"  🎨 마스크 픽셀값: {unique_values}\")\n",
    "            \n",
    "            robot_pixels = np.sum(mask > 127)\n",
    "            total_pixels = mask.shape[0] * mask.shape[1]\n",
    "            robot_ratio = robot_pixels / total_pixels * 100\n",
    "            print(f\"  🤖 로봇팔 비율: {robot_ratio:.1f}%\")\n",
    "            \n",
    "            print(f\"  ✅ 정상\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ 오류: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10474d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 성능 지표 계산 함수들\n",
    "# ===============================\n",
    "\n",
    "def calculate_iou(pred, target, num_classes=2):\n",
    "    \"\"\"IoU 계산\"\"\"\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        target_cls = (target == cls)\n",
    "        \n",
    "        intersection = torch.logical_and(pred_cls, target_cls).sum()\n",
    "        union = torch.logical_or(pred_cls, target_cls).sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = 1.0  # 해당 클래스가 없는 경우\n",
    "        else:\n",
    "            iou = intersection.float() / union.float()\n",
    "        \n",
    "        ious.append(iou)\n",
    "    \n",
    "    return torch.stack(ious)\n",
    "\n",
    "def calculate_dice(pred, target, num_classes=2):\n",
    "    \"\"\"Dice Score 계산\"\"\"\n",
    "    dices = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        target_cls = (target == cls)\n",
    "        \n",
    "        intersection = torch.logical_and(pred_cls, target_cls).sum()\n",
    "        total = pred_cls.sum() + target_cls.sum()\n",
    "        \n",
    "        if total == 0:\n",
    "            dice = 1.0  # 해당 클래스가 없는 경우\n",
    "        else:\n",
    "            dice = (2.0 * intersection.float()) / total.float()\n",
    "        \n",
    "        dices.append(dice)\n",
    "    \n",
    "    return torch.stack(dices)\n",
    "\n",
    "def calculate_pixel_accuracy(pred, target):\n",
    "    \"\"\"Pixel Accuracy 계산\"\"\"\n",
    "    correct = (pred == target).sum()\n",
    "    total = target.numel()\n",
    "    return correct.float() / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SegFormer 모델 정의\n",
    "# ===============================\n",
    "\n",
    "class SegFormerForRobotArm(nn.Module):\n",
    "    def __init__(self, num_classes=2, model_name=\"nvidia/mit-b2\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # SegFormer 모델 로드 (pretrained MiT 백본 포함)\n",
    "        # model_name 옵션:\n",
    "        # - nvidia/mit-b0: 3.7M params (빠름, 가벼움)\n",
    "        # - nvidia/mit-b1: 14M params  \n",
    "        # - nvidia/mit-b2: 25M params (권장, 균형점)\n",
    "        # - nvidia/mit-b3: 45M params (더 높은 성능)\n",
    "        # - nvidia/mit-b4: 62M params\n",
    "        # - nvidia/mit-b5: 82M params (최고 성능, 느림)\n",
    "        \n",
    "        print(f\"🏗️ SegFormer 모델 로딩: {model_name}\")\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # 모델 파라미터 수 출력\n",
    "        total_params = sum(p.numel() for p in self.segformer.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.segformer.parameters() if p.requires_grad)\n",
    "        print(f\"📊 총 파라미터: {total_params:,}\")\n",
    "        print(f\"📊 훈련 가능 파라미터: {trainable_params:,}\")\n",
    "        \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.segformer(pixel_values=pixel_values)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # SegFormer 출력을 입력 크기로 업샘플링\n",
    "        # 입력: [B, C, H, W] -> 출력: [B, num_classes, H, W]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=pixel_values.shape[-2:],  # (H, W)\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        return upsampled_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 손실 함수 정의\n",
    "# ===============================\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # CrossEntropyLoss 가중치\n",
    "        self.beta = beta    # DiceLoss 가중치\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def dice_loss(self, pred, target, smooth=1e-6):\n",
    "        \"\"\"Dice Loss 계산\"\"\"\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        \n",
    "        dice_losses = []\n",
    "        for cls in range(pred.shape[1]):\n",
    "            pred_cls = pred[:, cls, :, :]\n",
    "            target_cls = (target == cls).float()\n",
    "            \n",
    "            intersection = (pred_cls * target_cls).sum(dim=(1, 2))\n",
    "            union = pred_cls.sum(dim=(1, 2)) + target_cls.sum(dim=(1, 2))\n",
    "            \n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_loss = 1.0 - dice\n",
    "            dice_losses.append(dice_loss.mean())\n",
    "        \n",
    "        return sum(dice_losses) / len(dice_losses)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce_loss = self.ce_loss(pred, target)\n",
    "        dice_loss = self.dice_loss(pred, target)\n",
    "        \n",
    "        total_loss = self.alpha * ce_loss + self.beta * dice_loss\n",
    "        return total_loss, ce_loss, dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2abbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 훈련 및 검증 함수\n",
    "# ===============================\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"한 에포크 훈련\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_ce_loss = 0.0\n",
    "    running_dice_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice_score = 0.0\n",
    "    running_pixel_acc = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Train Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        images = batch['image'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 예측\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 첫 번째 배치에서 크기 확인 (디버깅용)\n",
    "        if batch_idx == 0 and epoch == 1:\n",
    "            print(f\"\\n🔍 첫 번째 훈련 배치 텐서 크기:\")\n",
    "            print(f\"  입력 이미지: {images.shape}\")\n",
    "            print(f\"  타겟 마스크: {masks.shape}\")\n",
    "            print(f\"  모델 출력: {outputs.shape}\")\n",
    "            \n",
    "            if images.shape[-2:] != outputs.shape[-2:]:\n",
    "                print(f\"  ⚠️ 크기 불일치 감지!\")\n",
    "                print(f\"    입력 크기: {images.shape[-2:]}\")\n",
    "                print(f\"    출력 크기: {outputs.shape[-2:]}\")\n",
    "            else:\n",
    "                print(f\"  ✅ 크기 일치 확인\")\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss, ce_loss, dice_loss = criterion(outputs, masks)\n",
    "        \n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 성능 지표 계산\n",
    "        with torch.no_grad():\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            iou = calculate_iou(pred_masks, masks).mean()\n",
    "            dice_score = calculate_dice(pred_masks, masks).mean()\n",
    "            pixel_acc = calculate_pixel_accuracy(pred_masks, masks)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_ce_loss += ce_loss.item()\n",
    "            running_dice_loss += dice_loss.item()\n",
    "            running_iou += iou.item()\n",
    "            running_dice_score += dice_score.item()\n",
    "            running_pixel_acc += pixel_acc.item()\n",
    "        \n",
    "        # 진행률 업데이트\n",
    "        if batch_idx % 10 == 0:\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'IoU': f'{iou.item():.4f}',\n",
    "                'Dice': f'{dice_score.item():.4f}',\n",
    "                'PixelAcc': f'{pixel_acc.item():.4f}'\n",
    "            })\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    return {\n",
    "        'loss': running_loss / num_batches,\n",
    "        'ce_loss': running_ce_loss / num_batches,\n",
    "        'dice_loss': running_dice_loss / num_batches,\n",
    "        'iou': running_iou / num_batches,\n",
    "        'dice_score': running_dice_score / num_batches,\n",
    "        'pixel_accuracy': running_pixel_acc / num_batches\n",
    "    }\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device, epoch):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_ce_loss = 0.0\n",
    "    running_dice_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice_score = 0.0\n",
    "    running_pixel_acc = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=f'Val Epoch {epoch}')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss, ce_loss, dice_loss = criterion(outputs, masks)\n",
    "            \n",
    "            # 성능 지표 계산\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            iou = calculate_iou(pred_masks, masks).mean()\n",
    "            dice_score = calculate_dice(pred_masks, masks).mean()\n",
    "            pixel_acc = calculate_pixel_accuracy(pred_masks, masks)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_ce_loss += ce_loss.item()\n",
    "            running_dice_loss += dice_loss.item()\n",
    "            running_iou += iou.item()\n",
    "            running_dice_score += dice_score.item()\n",
    "            running_pixel_acc += pixel_acc.item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'IoU': f'{iou.item():.4f}',\n",
    "                'Dice': f'{dice_score.item():.4f}',\n",
    "                'PixelAcc': f'{pixel_acc.item():.4f}'\n",
    "            })\n",
    "    \n",
    "    num_batches = len(val_loader)\n",
    "    return {\n",
    "        'loss': running_loss / num_batches,\n",
    "        'ce_loss': running_ce_loss / num_batches,\n",
    "        'dice_loss': running_dice_loss / num_batches,\n",
    "        'iou': running_iou / num_batches,\n",
    "        'dice_score': running_dice_score / num_batches,\n",
    "        'pixel_accuracy': running_pixel_acc / num_batches\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 결과 시각화 함수\n",
    "# ===============================\n",
    "\n",
    "def visualize_predictions(model, val_loader, device, num_samples=3):\n",
    "    \"\"\"예측 결과 시각화\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 역정규화를 위한 함수\n",
    "    def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        for t, m, s in zip(tensor, mean, std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return torch.clamp(tensor, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # 첫 번째 이미지만 시각화\n",
    "            image = images[0].cpu()\n",
    "            mask = masks[0].cpu().numpy()\n",
    "            pred_mask = pred_masks[0].cpu().numpy()\n",
    "            \n",
    "            # 이미지 역정규화\n",
    "            image = denormalize(image)\n",
    "            image = image.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # 원본 이미지\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # 실제 마스크\n",
    "            axes[i, 1].imshow(mask, cmap='gray')\n",
    "            axes[i, 1].set_title(f'Ground Truth Mask {i+1}')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # 예측 마스크\n",
    "            axes[i, 2].imshow(pred_mask, cmap='gray')\n",
    "            axes[i, 2].set_title(f'Predicted Mask {i+1}')\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49891e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 메인 훈련 함수\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    # 하이퍼파라미터 설정\n",
    "    BATCH_SIZE = 8  # GPU 메모리에 따라 조정\n",
    "    IMAGE_SIZE = 512\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_EPOCHS = 50\n",
    "    PATIENCE = 10  # Early stopping\n",
    "    \n",
    "    # 모델 크기 선택 (성능 vs 속도 트레이드오프)\n",
    "    MODEL_VARIANTS = {\n",
    "        'small': 'nvidia/mit-b0',    # 빠름, 가벼움\n",
    "        'medium': 'nvidia/mit-b2',   # 권장 (균형점)\n",
    "        'large': 'nvidia/mit-b3',    # 높은 성능\n",
    "        'xlarge': 'nvidia/mit-b4'    # 최고 성능 (메모리 많이 필요)\n",
    "    }\n",
    "    \n",
    "    # 증강 레벨 선택\n",
    "    AUGMENTATION_LEVELS = {\n",
    "        'light': '가벼운 증강 (빠른 훈련)',\n",
    "        'moderate': '중간 증강 (권장)',\n",
    "        'heavy': '강한 증강 (더 robust한 모델)'\n",
    "    }\n",
    "    \n",
    "    # 설정 (필요에 따라 변경)\n",
    "    MODEL_SIZE = 'medium'  # 'small', 'medium', 'large', 'xlarge'\n",
    "    AUGMENTATION_LEVEL = 'moderate'  # 'light', 'moderate', 'heavy'\n",
    "    \n",
    "    print(\"🚀 SegFormer 로봇팔 Segmentation 훈련 시작\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"🏗️ 모델 크기: {MODEL_SIZE} ({MODEL_VARIANTS[MODEL_SIZE]})\")\n",
    "    print(f\"🔄 데이터 증강: {AUGMENTATION_LEVEL} ({AUGMENTATION_LEVELS[AUGMENTATION_LEVEL]})\")\n",
    "    \n",
    "    # 1. 데이터 로딩 및 매칭\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    \n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        print(\"❌ 매칭된 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 2. 데이터 품질 검증\n",
    "    # verify_data_quality(image_paths, mask_paths, num_samples=3)\n",
    "    \n",
    "    # 3. Train/Validation 분할 (stratified by view)\n",
    "    # 시점 정보 추출 (경로에서)\n",
    "    views = []\n",
    "    for img_path in image_paths:\n",
    "        if 'left' in img_path:\n",
    "            views.append('left')\n",
    "        elif 'right' in img_path:\n",
    "            views.append('right')\n",
    "        elif 'top' in img_path:\n",
    "            views.append('top')\n",
    "        else:\n",
    "            views.append('unknown')\n",
    "    \n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "        image_paths, mask_paths,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=views\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📊 데이터 분할 결과:\")\n",
    "    print(f\"  훈련 데이터: {len(train_img_paths)}개\")\n",
    "    print(f\"  검증 데이터: {len(val_img_paths)}개\")\n",
    "    \n",
    "    # 4. 데이터셋 및 데이터로더 생성\n",
    "    train_transforms = get_train_transforms(IMAGE_SIZE, AUGMENTATION_LEVEL)\n",
    "    val_transforms = get_val_transforms(IMAGE_SIZE)\n",
    "    \n",
    "    train_dataset = RobotArmDataset(\n",
    "        train_img_paths, train_mask_paths, \n",
    "        transform=train_transforms, \n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = RobotArmDataset(\n",
    "        val_img_paths, val_mask_paths, \n",
    "        transform=val_transforms, \n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📈 배치 정보:\")\n",
    "    print(f\"  훈련 배치 수: {len(train_loader)}\")\n",
    "    print(f\"  검증 배치 수: {len(val_loader)}\")\n",
    "    print(f\"  배치 크기: {BATCH_SIZE}\")\n",
    "    \n",
    "    # 5. 모델 생성\n",
    "    print(f\"\\n🏗️ 모델 생성 중...\")\n",
    "    model = SegFormerForRobotArm(\n",
    "        num_classes=2, \n",
    "        model_name=MODEL_VARIANTS[MODEL_SIZE]\n",
    "    )\n",
    "    \n",
    "    # Multi-GPU 사용\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"🖥️ {torch.cuda.device_count()}개 GPU 사용\")\n",
    "        model = DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 6. 손실 함수 및 옵티마이저\n",
    "    criterion = CombinedLoss(alpha=0.7, beta=0.3)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    \n",
    "    # 학습률 스케줄러\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "    \n",
    "    # 7. 훈련 기록을 위한 변수들\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    best_val_iou = 0.0\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"\\n🎯 훈련 시작!\")\n",
    "    print(f\"  총 에포크: {NUM_EPOCHS}\")\n",
    "    print(f\"  학습률: {LEARNING_RATE}\")\n",
    "    print(f\"  Early Stopping 기준: {PATIENCE} 에포크\")\n",
    "    \n",
    "    # 8. 훈련 루프\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 훈련\n",
    "        train_metrics = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 검증\n",
    "        val_metrics = validate_epoch(model, val_loader, criterion, device, epoch)\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # 학습률 변경 감지 및 출력\n",
    "        if new_lr < old_lr:\n",
    "            print(f\"  📉 학습률 감소: {old_lr:.2e} → {new_lr:.2e}\")\n",
    "        \n",
    "        # 기록 저장\n",
    "        train_history.append(train_metrics)\n",
    "        val_history.append(val_metrics)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f\"\\n📊 Epoch {epoch}/{NUM_EPOCHS} 결과 (소요시간: {epoch_time:.2f}초)\")\n",
    "        print(f\"  Train - Loss: {train_metrics['loss']:.4f}, IoU: {train_metrics['iou']:.4f}, \"\n",
    "              f\"Dice: {train_metrics['dice_score']:.4f}, PixelAcc: {train_metrics['pixel_accuracy']:.4f}\")\n",
    "        print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, IoU: {val_metrics['iou']:.4f}, \"\n",
    "              f\"Dice: {val_metrics['dice_score']:.4f}, PixelAcc: {val_metrics['pixel_accuracy']:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_metrics['iou'] > best_val_iou:\n",
    "            best_val_iou = val_metrics['iou']\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # 모델 저장\n",
    "            if isinstance(model, DataParallel):\n",
    "                model_state = model.module.state_dict()\n",
    "            else:\n",
    "                model_state = model.state_dict()\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model_state,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_iou': val_metrics['iou'],\n",
    "                'val_dice': val_metrics['dice_score'],\n",
    "                'train_history': train_history,\n",
    "                'val_history': val_history\n",
    "            }, 'best_segformer_robot_arm.pth')\n",
    "            \n",
    "            print(f\"  🎉 새로운 최고 성능! IoU: {best_val_iou:.4f} (Epoch {epoch})\")\n",
    "            \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  ⏳ 성능 개선 없음 ({patience_counter}/{PATIENCE})\")\n",
    "        \n",
    "        # Early Stopping\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"\\n🛑 Early Stopping! 최고 성능: IoU {best_val_iou:.4f} (Epoch {best_epoch})\")\n",
    "            break\n",
    "        \n",
    "        # 매 5 에포크마다 예측 결과 시각화\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"\\n🖼️ 예측 결과 시각화 (Epoch {epoch})\")\n",
    "            visualize_predictions(model, val_loader, device, num_samples=3)\n",
    "    \n",
    "    # 9. 훈련 완료 후 최종 결과\n",
    "    print(f\"\\n🎊 훈련 완료!\")\n",
    "    print(f\"  최고 성능: IoU {best_val_iou:.4f} (Epoch {best_epoch})\")\n",
    "    print(f\"  모델 저장 위치: best_segformer_robot_arm.pth\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # 11. 최종 예측 결과 시각화\n",
    "    print(f\"\\n🖼️ 최종 예측 결과\")\n",
    "    visualize_predictions(model, val_loader, device, num_samples=5)\n",
    "    \n",
    "    # 12. 성능 지표 요약\n",
    "    # print_final_metrics(val_history, best_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 메인 훈련 실행\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0dbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 간단한 SegFormer 모델 성능 평가 코드\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_best_model(checkpoint_path, device):\n",
    "    \"\"\"저장된 최고 성능 모델 로드\"\"\"\n",
    "    print(f\"📂 모델 로딩: {checkpoint_path}\")\n",
    "    \n",
    "    # 모델 생성 (기존 클래스 사용)\n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "    \n",
    "    # 체크포인트 로드\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✅ 모델 로드 완료 (Epoch {checkpoint['epoch']}, IoU: {checkpoint['val_iou']:.4f})\")\n",
    "    return model, checkpoint\n",
    "\n",
    "def calculate_metrics(pred_masks, true_masks):\n",
    "    \"\"\"기본 성능 지표 계산\"\"\"\n",
    "    # 전체 픽셀 정확도\n",
    "    pixel_acc = (pred_masks == true_masks).float().mean()\n",
    "    \n",
    "    # 클래스별 IoU 계산\n",
    "    ious = []\n",
    "    dices = []\n",
    "    \n",
    "    for cls in range(2):  # 배경(0), 로봇팔(1)\n",
    "        pred_cls = (pred_masks == cls)\n",
    "        true_cls = (true_masks == cls)\n",
    "        \n",
    "        # IoU\n",
    "        intersection = (pred_cls & true_cls).sum().float()\n",
    "        union = (pred_cls | true_cls).sum().float()\n",
    "        iou = intersection / union if union > 0 else 1.0\n",
    "        \n",
    "        # Dice Score\n",
    "        dice = (2.0 * intersection) / (pred_cls.sum() + true_cls.sum()) if (pred_cls.sum() + true_cls.sum()) > 0 else 1.0\n",
    "        \n",
    "        ious.append(iou.item())\n",
    "        dices.append(dice.item())\n",
    "    \n",
    "    return {\n",
    "        'pixel_accuracy': pixel_acc.item(),\n",
    "        'background_iou': ious[0],\n",
    "        'robot_arm_iou': ious[1],\n",
    "        'mean_iou': np.mean(ious),\n",
    "        'background_dice': dices[0],\n",
    "        'robot_arm_dice': dices[1],\n",
    "        'mean_dice': np.mean(dices)\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"모델 성능 평가\"\"\"\n",
    "    print(\"\\n🔍 모델 성능 평가 시작...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_metrics = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"평가 중\"):\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            # 예측\n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # 메트릭 계산\n",
    "            metrics = calculate_metrics(pred_masks, masks)\n",
    "            all_metrics.append(metrics)\n",
    "    \n",
    "    # 전체 평균 계산\n",
    "    avg_metrics = {}\n",
    "    for key in all_metrics[0].keys():\n",
    "        avg_metrics[key] = np.mean([m[key] for m in all_metrics])\n",
    "        avg_metrics[key + '_std'] = np.std([m[key] for m in all_metrics])\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "def visualize_sample_predictions(model, val_loader, device, num_samples=3):\n",
    "    \"\"\"샘플 예측 결과 시각화\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        # ImageNet 정규화 역변환\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        return torch.clamp(tensor * std + mean, 0, 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # 첫 번째 이미지만 시각화\n",
    "            image = denormalize(images[0].cpu()).permute(1, 2, 0).numpy()\n",
    "            true_mask = masks[0].cpu().numpy()\n",
    "            pred_mask = pred_masks[0].cpu().numpy()\n",
    "            \n",
    "            # IoU 계산\n",
    "            pred_robot = (pred_mask == 1)\n",
    "            true_robot = (true_mask == 1)\n",
    "            intersection = np.logical_and(pred_robot, true_robot).sum()\n",
    "            union = np.logical_or(pred_robot, true_robot).sum()\n",
    "            iou = intersection / union if union > 0 else 1.0\n",
    "            \n",
    "            # 시각화\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(true_mask, cmap='gray')\n",
    "            axes[i, 1].set_title('Ground Truth')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(pred_mask, cmap='gray')\n",
    "            axes[i, 2].set_title(f'Prediction (IoU: {iou:.3f})')\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('evaluation_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def print_evaluation_results(metrics):\n",
    "    \"\"\"평가 결과 출력\"\"\"\n",
    "    print(\"\\n📊 모델 성능 평가 결과\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"🎯 전체 성능:\")\n",
    "    print(f\"  Pixel Accuracy: {metrics['pixel_accuracy']:.4f} ± {metrics['pixel_accuracy_std']:.4f}\")\n",
    "    print(f\"  Mean IoU: {metrics['mean_iou']:.4f} ± {metrics['mean_iou_std']:.4f}\")\n",
    "    print(f\"  Mean Dice: {metrics['mean_dice']:.4f} ± {metrics['mean_dice_std']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n📋 클래스별 성능:\")\n",
    "    print(f\"  배경 (Background):\")\n",
    "    print(f\"    IoU: {metrics['background_iou']:.4f} ± {metrics['background_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['background_dice']:.4f} ± {metrics['background_dice_std']:.4f}\")\n",
    "    \n",
    "    print(f\"  로봇팔 (Robot Arm):\")\n",
    "    print(f\"    IoU: {metrics['robot_arm_iou']:.4f} ± {metrics['robot_arm_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['robot_arm_dice']:.4f} ± {metrics['robot_arm_dice_std']:.4f}\")\n",
    "    \n",
    "    # 성능 등급\n",
    "    robot_iou = metrics['robot_arm_iou']\n",
    "    if robot_iou >= 0.95:\n",
    "        grade = \"🥇 Excellent\"\n",
    "    elif robot_iou >= 0.90:\n",
    "        grade = \"🥈 Very Good\"\n",
    "    elif robot_iou >= 0.85:\n",
    "        grade = \"🥉 Good\"\n",
    "    elif robot_iou >= 0.80:\n",
    "        grade = \"✅ Acceptable\"\n",
    "    else:\n",
    "        grade = \"⚠️ Needs Improvement\"\n",
    "    \n",
    "    print(f\"\\n🎖️ 로봇팔 성능 등급: {grade}\")\n",
    "\n",
    "def run_simple_evaluation():\n",
    "    \"\"\"간단한 평가 실행\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint_path = 'best_segformer_robot_arm.pth'\n",
    "    \n",
    "    # 데이터 로더 생성 (기존 훈련 코드와 동일)\n",
    "    print(\"📊 데이터 로딩 중...\")\n",
    "    \n",
    "    # 기존 훈련 코드에서 사용한 함수들 (import 필요)\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    \n",
    "    # 데이터 매칭 (기존 함수 사용)\n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "    \n",
    "    # 시점 정보 추출\n",
    "    views = []\n",
    "    for img_path in image_paths:\n",
    "        if 'left' in img_path:\n",
    "            views.append('left')\n",
    "        elif 'right' in img_path:\n",
    "            views.append('right')\n",
    "        elif 'top' in img_path:\n",
    "            views.append('top')\n",
    "        else:\n",
    "            views.append('unknown')\n",
    "    \n",
    "    # Train/Validation 분할 (기존과 동일한 방식)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "        image_paths, mask_paths,\n",
    "        test_size=0.2,\n",
    "        random_state=42,  # 동일한 분할 보장\n",
    "        stratify=views\n",
    "    )\n",
    "    \n",
    "    # Validation 데이터셋 생성\n",
    "    val_transforms = get_val_transforms(512)  # 기존 함수 사용\n",
    "    val_dataset = RobotArmDataset(\n",
    "        val_img_paths, val_mask_paths, \n",
    "        transform=val_transforms, \n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # Validation 데이터로더 생성\n",
    "    from torch.utils.data import DataLoader\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=8, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"검증 데이터: {len(val_img_paths)}개\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    model, checkpoint = load_best_model(checkpoint_path, device)\n",
    "    \n",
    "    # 성능 평가\n",
    "    metrics = evaluate_model(model, val_loader, device)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print_evaluation_results(metrics)\n",
    "    \n",
    "    # 샘플 시각화\n",
    "    print(f\"\\n🖼️ 샘플 예측 결과 시각화\")\n",
    "    visualize_sample_predictions(model, val_loader, device, num_samples=3)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 방법 1: 독립적으로 실행 (데이터 로더 새로 생성)\n",
    "if __name__ == \"__main__\":\n",
    "    # 필요한 함수들이 이미 정의되어 있어야 함\n",
    "    # match_image_mask_pairs, get_val_transforms, RobotArmDataset 등\n",
    "    \n",
    "    metrics = run_simple_evaluation()\n",
    "    print(f\"\\n🎊 평가 완료!\")\n",
    "    print(f\"결과 이미지: evaluation_samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f476c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_best_model(checkpoint_path, device):\n",
    "    \"\"\"저장된 최고 성능 모델 로드\"\"\"\n",
    "    print(f\"📂 모델 로딩: {checkpoint_path}\")\n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"✅ 모델 로드 완료 (Epoch {checkpoint['epoch']}, IoU: {checkpoint['val_iou']:.4f})\")\n",
    "    return model, checkpoint\n",
    "\n",
    "def calculate_metrics(pred_masks, true_masks):\n",
    "    \"\"\"기본 성능 지표 계산\"\"\"\n",
    "    pixel_acc = (pred_masks == true_masks).float().mean()\n",
    "    ious, dices = [], []\n",
    "    for cls in range(2):\n",
    "        pred_cls = (pred_masks == cls)\n",
    "        true_cls = (true_masks == cls)\n",
    "        intersection = (pred_cls & true_cls).sum().float()\n",
    "        union = (pred_cls | true_cls).sum().float()\n",
    "        iou = intersection / union if union > 0 else 1.0\n",
    "        dice = (2.0 * intersection) / (pred_cls.sum() + true_cls.sum()) if (pred_cls.sum() + true_cls.sum()) > 0 else 1.0\n",
    "        ious.append(iou.item())\n",
    "        dices.append(dice.item())\n",
    "    return {\n",
    "        'pixel_accuracy': pixel_acc.item(),\n",
    "        'background_iou': ious[0],\n",
    "        'robot_arm_iou': ious[1],\n",
    "        'mean_iou': np.mean(ious),\n",
    "        'background_dice': dices[0],\n",
    "        'robot_arm_dice': dices[1],\n",
    "        'mean_dice': np.mean(dices)\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"모델 성능 평가\"\"\"\n",
    "    print(\"\\n🔍 모델 성능 평가 시작...\")\n",
    "    model.eval()\n",
    "    all_metrics = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"평가 중\"):\n",
    "            images = batch['image'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            metrics = calculate_metrics(pred_masks, masks)\n",
    "            all_metrics.append(metrics)\n",
    "    avg_metrics = {}\n",
    "    for key in all_metrics[0].keys():\n",
    "        avg_metrics[key] = np.mean([m[key] for m in all_metrics])\n",
    "        avg_metrics[key + '_std'] = np.std([m[key] for m in all_metrics])\n",
    "    return avg_metrics\n",
    "\n",
    "def print_evaluation_results(metrics):\n",
    "    print(\"\\n📊 모델 성능 평가 결과\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"🎯 전체 성능:\")\n",
    "    print(f\"  Pixel Accuracy: {metrics['pixel_accuracy']:.4f} ± {metrics['pixel_accuracy_std']:.4f}\")\n",
    "    print(f\"  Mean IoU: {metrics['mean_iou']:.4f} ± {metrics['mean_iou_std']:.4f}\")\n",
    "    print(f\"  Mean Dice: {metrics['mean_dice']:.4f} ± {metrics['mean_dice_std']:.4f}\")\n",
    "    print(f\"\\n📋 클래스별 성능:\")\n",
    "    print(f\"  배경 (Background):\")\n",
    "    print(f\"    IoU: {metrics['background_iou']:.4f} ± {metrics['background_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['background_dice']:.4f} ± {metrics['background_dice_std']:.4f}\")\n",
    "    print(f\"  로봇팔 (Robot Arm):\")\n",
    "    print(f\"    IoU: {metrics['robot_arm_iou']:.4f} ± {metrics['robot_arm_iou_std']:.4f}\")\n",
    "    print(f\"    Dice: {metrics['robot_arm_dice']:.4f} ± {metrics['robot_arm_dice_std']:.4f}\")\n",
    "    robot_iou = metrics['robot_arm_iou']\n",
    "    if robot_iou >= 0.95:\n",
    "        grade = \"🥇 Excellent\"\n",
    "    elif robot_iou >= 0.90:\n",
    "        grade = \"🥈 Very Good\"\n",
    "    elif robot_iou >= 0.85:\n",
    "        grade = \"🥉 Good\"\n",
    "    elif robot_iou >= 0.80:\n",
    "        grade = \"✅ Acceptable\"\n",
    "    else:\n",
    "        grade = \"⚠️ Needs Improvement\"\n",
    "    print(f\"\\n🎖️ 로봇팔 성능 등급: {grade}\")\n",
    "\n",
    "def plot_key_metrics(metrics):\n",
    "    \"\"\"핵심 성능 지표 시각화\"\"\"\n",
    "    keys = ['mean_iou', 'mean_dice', 'pixel_accuracy']\n",
    "    labels = ['Mean IoU', 'Mean Dice', 'Pixel Accuracy']\n",
    "    values = [metrics[k] for k in keys]\n",
    "    stds = [metrics[k + '_std'] for k in keys]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(labels, values, yerr=stds, capsize=5, color='skyblue')\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f\"{value:.3f}\",\n",
    "                 ha='center', va='bottom', fontsize=11)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('SegFormer Evaluation Metrics')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metric_bar_chart.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "def run_simple_evaluation():\n",
    "    \"\"\"간단한 평가 실행\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint_path = 'best_segformer_robot_arm.pth'\n",
    "\n",
    "    # 데이터 로드\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "\n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "\n",
    "    views = []\n",
    "    for img_path in image_paths:\n",
    "        if 'left' in img_path:\n",
    "            views.append('left')\n",
    "        elif 'right' in img_path:\n",
    "            views.append('right')\n",
    "        elif 'top' in img_path:\n",
    "            views.append('top')\n",
    "        else:\n",
    "            views.append('unknown')\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
    "        image_paths, mask_paths,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=views\n",
    "    )\n",
    "\n",
    "    val_transforms = get_val_transforms(512)\n",
    "    val_dataset = RobotArmDataset(val_img_paths, val_mask_paths, transform=val_transforms, is_train=False)\n",
    "    from torch.utils.data import DataLoader\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    print(f\"검증 데이터: {len(val_img_paths)}개\")\n",
    "\n",
    "    model, checkpoint = load_best_model(checkpoint_path, device)\n",
    "    metrics = evaluate_model(model, val_loader, device)\n",
    "    print_evaluation_results(metrics)\n",
    "    plot_key_metrics(metrics)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    metrics = run_simple_evaluation()\n",
    "    print(f\"\\n🎊 평가 완료! 시각화 저장됨: metric_bar_chart.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 랜덤 샘플 모델 테스트 및 시각화\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_test_transforms(image_size=512):\n",
    "    \"\"\"테스트용 전처리 (정규화만)\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def load_model_for_test(checkpoint_path, device):\n",
    "    \"\"\"테스트용 모델 로드\"\"\"\n",
    "    print(f\"📂 모델 로딩: {checkpoint_path}\")\n",
    "    \n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✅ 모델 로드 완료 (Epoch {checkpoint['epoch']}, IoU: {checkpoint['val_iou']:.4f})\")\n",
    "    return model\n",
    "\n",
    "def predict_single_image(model, image_path, mask_path, transform, device):\n",
    "    \"\"\"단일 이미지 예측\"\"\"\n",
    "    # 원본 이미지 로드\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    original_image = image.copy()\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    \n",
    "    # 마스크 로드 (정답)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = (mask > 127).astype(np.uint8)\n",
    "    original_mask = mask.copy()\n",
    "    \n",
    "    # 전처리 (이미지와 마스크 모두 512x512로 리사이즈)\n",
    "    transformed = transform(image=image, mask=mask)\n",
    "    image_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "    resized_mask = transformed['mask']  # 512x512로 리사이즈된 마스크\n",
    "    \n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        pred_mask = torch.argmax(output, dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    # 예측 마스크를 원본 크기로 다시 리사이즈\n",
    "    pred_mask_resized = cv2.resize(\n",
    "        pred_mask.astype(np.uint8), \n",
    "        (original_width, original_height), \n",
    "        interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "    \n",
    "    # IoU 계산 (원본 크기에서)\n",
    "    pred_robot = (pred_mask_resized == 1)\n",
    "    true_robot = (original_mask == 1)\n",
    "    intersection = np.logical_and(pred_robot, true_robot).sum()\n",
    "    union = np.logical_or(pred_robot, true_robot).sum()\n",
    "    iou = intersection / union if union > 0 else 1.0\n",
    "    \n",
    "    # Dice Score 계산 (원본 크기에서)\n",
    "    dice = (2.0 * intersection) / (pred_robot.sum() + true_robot.sum()) if (pred_robot.sum() + true_robot.sum()) > 0 else 1.0\n",
    "    \n",
    "    return {\n",
    "        'original_image': original_image,\n",
    "        'true_mask': original_mask,\n",
    "        'pred_mask': pred_mask_resized,  # 원본 크기로 복원된 예측 마스크\n",
    "        'pred_mask_512': pred_mask,      # 512x512 예측 마스크 (시각화용)\n",
    "        'iou': iou,\n",
    "        'dice': dice,\n",
    "        'image_path': image_path,\n",
    "        'mask_path': mask_path,\n",
    "        'original_size': (original_height, original_width)\n",
    "    }\n",
    "\n",
    "def random_sample_test(model, image_paths, mask_paths, num_samples=10, device='cuda'):\n",
    "    \"\"\"랜덤 샘플링으로 모델 테스트\"\"\"\n",
    "    print(f\"🎲 랜덤 샘플링 테스트 시작 ({num_samples}개 샘플)\")\n",
    "    \n",
    "    # 랜덤 인덱스 선택\n",
    "    total_samples = len(image_paths)\n",
    "    random_indices = random.sample(range(total_samples), min(num_samples, total_samples))\n",
    "    \n",
    "    transform = get_test_transforms()\n",
    "    results = []\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        print(f\"  처리 중: {i+1}/{len(random_indices)} - {Path(image_paths[idx]).name}\")\n",
    "        \n",
    "        result = predict_single_image(\n",
    "            model, \n",
    "            image_paths[idx], \n",
    "            mask_paths[idx], \n",
    "            transform, \n",
    "            device\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_test_results(results, save_path='test_results.png'):\n",
    "    \"\"\"테스트 결과 시각화\"\"\"\n",
    "    num_samples = len(results)\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        original_image = result['original_image']\n",
    "        true_mask = result['true_mask']\n",
    "        pred_mask = result['pred_mask']  # 원본 크기로 복원된 마스크\n",
    "        iou = result['iou']\n",
    "        dice = result['dice']\n",
    "        original_size = result['original_size']\n",
    "        \n",
    "        # 원본 이미지\n",
    "        axes[i, 0].imshow(original_image)\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}\\n{Path(result[\"image_path\"]).name}\\nSize: {original_size[1]}x{original_size[0]}', fontsize=9)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 실제 마스크\n",
    "        axes[i, 1].imshow(true_mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth Mask', fontsize=10)\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 예측 마스크 (원본 크기)\n",
    "        axes[i, 2].imshow(pred_mask, cmap='gray')\n",
    "        axes[i, 2].set_title(f'Predicted Mask\\nIoU: {iou:.3f}, Dice: {dice:.3f}', fontsize=10)\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"💾 결과 저장: {save_path}\")\n",
    "\n",
    "def visualize_test_results_comparison(results, save_path='test_comparison.png'):\n",
    "    \"\"\"원본 크기 vs 512x512 비교 시각화\"\"\"\n",
    "    num_samples = min(len(results), 3)  # 최대 3개만 비교\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5*num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        result = results[i]\n",
    "        original_image = result['original_image']\n",
    "        true_mask = result['true_mask']\n",
    "        pred_mask_original = result['pred_mask']  # 원본 크기\n",
    "        pred_mask_512 = result['pred_mask_512']   # 512x512\n",
    "        iou = result['iou']\n",
    "        \n",
    "        # 원본 이미지\n",
    "        axes[i, 0].imshow(original_image)\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}', fontsize=10)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 실제 마스크\n",
    "        axes[i, 1].imshow(true_mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth', fontsize=10)\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 예측 마스크 (512x512)\n",
    "        axes[i, 2].imshow(pred_mask_512, cmap='gray')\n",
    "        axes[i, 2].set_title('Prediction (512x512)', fontsize=10)\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # 예측 마스크 (원본 크기)\n",
    "        axes[i, 3].imshow(pred_mask_original, cmap='gray')\n",
    "        axes[i, 3].set_title(f'Prediction (Original)\\nIoU: {iou:.3f}', fontsize=10)\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"💾 비교 결과 저장: {save_path}\")\n",
    "\n",
    "def print_test_summary(results):\n",
    "    \"\"\"테스트 결과 요약 출력\"\"\"\n",
    "    ious = [r['iou'] for r in results]\n",
    "    dices = [r['dice'] for r in results]\n",
    "    \n",
    "    print(f\"\\n📊 테스트 결과 요약 ({len(results)}개 샘플)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"IoU Score:\")\n",
    "    print(f\"  평균: {np.mean(ious):.4f}\")\n",
    "    print(f\"  표준편차: {np.std(ious):.4f}\")\n",
    "    print(f\"  최소: {np.min(ious):.4f}\")\n",
    "    print(f\"  최대: {np.max(ious):.4f}\")\n",
    "    \n",
    "    print(f\"\\nDice Score:\")\n",
    "    print(f\"  평균: {np.mean(dices):.4f}\")\n",
    "    print(f\"  표준편차: {np.std(dices):.4f}\")\n",
    "    print(f\"  최소: {np.min(dices):.4f}\")\n",
    "    print(f\"  최대: {np.max(dices):.4f}\")\n",
    "    \n",
    "    # 성능별 분류\n",
    "    excellent = sum(1 for iou in ious if iou >= 0.95)\n",
    "    good = sum(1 for iou in ious if 0.9 <= iou < 0.95)\n",
    "    acceptable = sum(1 for iou in ious if 0.8 <= iou < 0.9)\n",
    "    poor = sum(1 for iou in ious if iou < 0.8)\n",
    "    \n",
    "    print(f\"\\n🎯 성능 분포:\")\n",
    "    print(f\"  Excellent (IoU ≥ 0.95): {excellent}개 ({excellent/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Good (0.9 ≤ IoU < 0.95): {good}개 ({good/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Acceptable (0.8 ≤ IoU < 0.9): {acceptable}개 ({acceptable/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Poor (IoU < 0.8): {poor}개 ({poor/len(results)*100:.1f}%)\")\n",
    "\n",
    "def analyze_by_view(results):\n",
    "    \"\"\"시점별 성능 분석\"\"\"\n",
    "    view_results = {'left': [], 'right': [], 'top': [], 'unknown': []}\n",
    "    \n",
    "    for result in results:\n",
    "        path = result['image_path']\n",
    "        if 'left' in path:\n",
    "            view = 'left'\n",
    "        elif 'right' in path:\n",
    "            view = 'right'\n",
    "        elif 'top' in path:\n",
    "            view = 'top'\n",
    "        else:\n",
    "            view = 'unknown'\n",
    "        \n",
    "        view_results[view].append(result['iou'])\n",
    "    \n",
    "    print(f\"\\n📊 시점별 성능 분석:\")\n",
    "    print(\"-\"*40)\n",
    "    for view, ious in view_results.items():\n",
    "        if ious:\n",
    "            print(f\"{view.upper()}: {len(ious)}개 - 평균 IoU {np.mean(ious):.4f}\")\n",
    "\n",
    "def run_random_test(num_samples=10):\n",
    "    \"\"\"랜덤 테스트 메인 함수\"\"\"\n",
    "    print(\"🚀 랜덤 샘플 모델 테스트 시작\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 1. 데이터 경로 수집\n",
    "    print(\"📊 데이터 수집 중...\")\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    \n",
    "    image_paths, mask_paths = match_image_mask_pairs(\n",
    "        original_images_root, \n",
    "        mask_images_root\n",
    "    )\n",
    "    \n",
    "    print(f\"총 {len(image_paths)}개 이미지-마스크 쌍 발견\")\n",
    "    \n",
    "    # 2. 모델 로드\n",
    "    model = load_model_for_test('best_segformer_robot_arm.pth', device)\n",
    "    \n",
    "    # 3. 랜덤 샘플링 테스트\n",
    "    results = random_sample_test(model, image_paths, mask_paths, num_samples, device)\n",
    "    \n",
    "    # 4. 결과 시각화\n",
    "    print(f\"\\n🖼️ 결과 시각화 중...\")\n",
    "    visualize_test_results(results, f'random_test_{num_samples}_samples.png')\n",
    "    \n",
    "    # 4-1. 추가: 크기 비교 시각화 (처음 3개 샘플)\n",
    "    if len(results) >= 3:\n",
    "        print(f\"🔍 크기 비교 시각화 중...\")\n",
    "        visualize_test_results_comparison(results[:3], f'size_comparison_{num_samples}_samples.png')\n",
    "    \n",
    "    # 5. 결과 분석\n",
    "    print_test_summary(results)\n",
    "    analyze_by_view(results)\n",
    "    \n",
    "    print(f\"\\n🎊 테스트 완료!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===============================\n",
    "# 특정 시점만 테스트하는 함수\n",
    "# ===============================\n",
    "\n",
    "def test_specific_view(view='left', num_samples=5):\n",
    "    \"\"\"특정 시점만 테스트\"\"\"\n",
    "    print(f\"🎯 {view.upper()} 시점 전용 테스트\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 데이터 수집\n",
    "    original_images_root = '/home/ibom002/dataset'\n",
    "    mask_images_root = '/home/ibom002/dataset'\n",
    "    image_paths, mask_paths = match_image_mask_pairs(original_images_root, mask_images_root)\n",
    "    \n",
    "    # 특정 시점만 필터링\n",
    "    view_image_paths = []\n",
    "    view_mask_paths = []\n",
    "    \n",
    "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "        if view in img_path:\n",
    "            view_image_paths.append(img_path)\n",
    "            view_mask_paths.append(mask_path)\n",
    "    \n",
    "    print(f\"{view.upper()} 시점 데이터: {len(view_image_paths)}개\")\n",
    "    \n",
    "    # 모델 로드 및 테스트\n",
    "    model = load_model_for_test('best_segformer_robot_arm.pth', device)\n",
    "    results = random_sample_test(model, view_image_paths, view_mask_paths, num_samples, device)\n",
    "    \n",
    "    # 시각화\n",
    "    visualize_test_results(results, f'{view}_view_test.png')\n",
    "    print_test_summary(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ===============================\n",
    "# 실행 부분\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 랜덤 10개 샘플 테스트\n",
    "    results = run_random_test(num_samples=10)\n",
    "    \n",
    "    # 또는 특정 시점만 테스트\n",
    "    # left_results = test_specific_view('left', num_samples=5)\n",
    "    # right_results = test_specific_view('right', num_samples=5)\n",
    "    # top_results = test_specific_view('top', num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a3ab0",
   "metadata": {},
   "source": [
    "원본이미지에 마스크 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4138c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ===============================\n",
    "# SegFormer 모델 정의\n",
    "# ===============================\n",
    "\n",
    "class SegFormerForRobotArm(nn.Module):\n",
    "    def __init__(self, num_classes=2, model_name=\"nvidia/mit-b2\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # SegFormer 모델 로드 (pretrained MiT 백본 포함)\n",
    "        # model_name 옵션:\n",
    "        # - nvidia/mit-b0: 3.7M params (빠름, 가벼움)\n",
    "        # - nvidia/mit-b1: 14M params  \n",
    "        # - nvidia/mit-b2: 25M params (권장, 균형점)\n",
    "        # - nvidia/mit-b3: 45M params (더 높은 성능)\n",
    "        # - nvidia/mit-b4: 62M params\n",
    "        # - nvidia/mit-b5: 82M params (최고 성능, 느림)\n",
    "        \n",
    "        print(f\"🏗️ SegFormer 모델 로딩: {model_name}\")\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # 모델 파라미터 수 출력\n",
    "        total_params = sum(p.numel() for p in self.segformer.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.segformer.parameters() if p.requires_grad)\n",
    "        print(f\"📊 총 파라미터: {total_params:,}\")\n",
    "        print(f\"📊 훈련 가능 파라미터: {trainable_params:,}\")\n",
    "        \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.segformer(pixel_values=pixel_values)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # SegFormer 출력을 입력 크기로 업샘플링\n",
    "        # 입력: [B, C, H, W] -> 출력: [B, num_classes, H, W]\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=pixel_values.shape[-2:],  # (H, W)\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        return upsampled_logits\n",
    "\n",
    "model = SegFormerForRobotArm(num_classes=2, model_name=\"nvidia/mit-b2\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def overlay_mask_on_image(image: np.ndarray, mask: np.ndarray, alpha=0.5, color=(0, 255, 0)):\n",
    "    \"\"\"원본 이미지 위에 초록색 마스크를 덧씌움\"\"\"\n",
    "    color_mask = np.zeros_like(image)\n",
    "    color_mask[mask == 1] = color\n",
    "    blended = cv2.addWeighted(image, 1 - alpha, color_mask, alpha, 0)\n",
    "    return blended\n",
    "\n",
    "def get_val_transforms(image_size=512):\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "def visualize_from_saved_model(image_path, model_path='best_segformer_robot_arm.pth', model_size='nvidia/mit-b2', image_size=512):\n",
    "    # 1. 이미지 불러오기\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    orig_np = np.array(image)\n",
    "\n",
    "    # 2. 변환 적용\n",
    "    transform = get_val_transforms(image_size)\n",
    "    transformed = transform(image=np.array(image))\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "\n",
    "    # 3. 모델 로드\n",
    "    model = SegFormerForRobotArm(num_classes=2, model_name=model_size)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 4. 추론 시간 측정\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        output = model(input_tensor)  # [1, C, H, W]\n",
    "        end = time.time()\n",
    "\n",
    "        pred_mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    print(f\"⏱️ 추론 시간: {(end - start)*1000:.2f} ms\")  # 또는 sec 단위로 보기 원하면 : .4f sec\n",
    "\n",
    "    # 5. 시각화\n",
    "    if orig_np.shape[:2] != pred_mask.shape:\n",
    "        pred_mask = cv2.resize(pred_mask, (orig_np.shape[1], orig_np.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    overlay = overlay_mask_on_image(orig_np, pred_mask, alpha=0.5, color=(0, 255, 0))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"SegFormer result\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 예시 사용\n",
    "image_path = \"/home/ibom002/dataset/Fr5_intertek_4th_250526/left/zed_38007749_left_1748249115.548.jpg\"\n",
    "visualize_from_saved_model(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c655451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
